from django.shortcuts import render, redirect
from django.contrib.auth.decorators import login_required, permission_required
from django.contrib.auth.mixins import LoginRequiredMixin
from django.views.generic import TemplateView
from django.http import JsonResponse, HttpResponse, Http404
from django.contrib import messages
from django.core import serializers
from django.apps import apps
from django.conf import settings
from django.utils.translation import gettext as _
from django.utils import timezone
from django.db import transaction
from django.db import models
from django.db.models.deletion import ProtectedError
from django.core.cache import cache
from django.template.defaultfilters import filesizeformat
from django.urls import reverse
import json
import os
import threading
import time
import logging
from datetime import datetime as dt_module
from openpyxl import Workbook
from decimal import Decimal

# Ø¥Ø¶Ø§ÙØ© AuditLog import
try:
    from core.models import AuditLog
    AUDIT_AVAILABLE = True
except ImportError:
    AUDIT_AVAILABLE = False

logger = logging.getLogger(__name__)


def log_audit(user, action, description, obj_id=None):
    """Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©"""
    if not AUDIT_AVAILABLE or not user:
        return
    
    try:
        AuditLog.objects.create(
            user=user,
            action_type=action,
            content_type='backup_system',
            object_id=obj_id,
            description=description
        )
    except Exception as e:
        logger.warning(f"ÙØ´Ù„ ÙÙŠ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø¯Ø« ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©: {str(e)}")


def get_backup_progress_data():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ‚Ø¯Ù… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù…Ù† cache"""
    return cache.get('backup_progress', {
        'is_running': False,
        'current_table': '',
        'processed_tables': 0,
        'total_tables': 0,
        'processed_records': 0,
        'total_records': 0,
        'percentage': 0,
        'status': 'idle',
        'error': None,
        'tables_status': [],
        'estimated_time': ''
    })

def set_backup_progress_data(data):
    """ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ‚Ø¯Ù… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ ÙÙŠ cache"""
    import time
    current_time = time.time()
    cache.set('backup_progress', data, timeout=3600)
    cache.set('backup_last_update', current_time, timeout=3600)
    
    # ØªØ­Ø¯ÙŠØ« Ø¢Ø®Ø± Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ© Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
    if 'percentage' in data:
        cache.set('backup_last_percentage', data['percentage'], timeout=3600)


def get_restore_progress_data():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ‚Ø¯Ù… Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù…Ù† cache"""
    return cache.get('restore_progress', {
        'is_running': False,
        'current_table': '',
        'processed_tables': 0,
        'total_tables': 0,
        'processed_records': 0,
        'total_records': 0,
        'percentage': 0,
        'status': 'idle',
        'error': None,
        'tables_status': [],
        'estimated_time': ''
    })


@login_required
def get_deletable_tables(request):
    """API ØªØ¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªÙŠ ÙŠÙ…ÙƒÙ† Ø­Ø°ÙÙ‡Ø§ Ù…Ø¹ ÙØ­Øµ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬.
    Ø³ØªØ±Ø¬Ø¹ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ØµØ±: { app_name, model_name, display_name, record_count, dependents: [labels], safe_to_delete }
    safe_to_delete True ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ø¢Ø®Ø± ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (FK) Ø¨Ø®Ù„Ø§Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø³ØªØ¨Ø¹Ø¯Ø©.
    """
    
    # ÙØ­Øµ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
    if not request.user.has_perm('backup.can_delete_advanced_data'):
        # ØªØ³Ø¬ÙŠÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ ØºÙŠØ± Ø§Ù„Ù…Ø³Ù…ÙˆØ­
        log_audit(request.user, 'denied', _('Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØµÙˆÙ„ Ù…Ø±ÙÙˆØ¶Ø© Ù„Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø­Ø°Ù - ØµÙ„Ø§Ø­ÙŠØ© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©'))
        return JsonResponse({'success': False, 'error': _('Ù„ÙŠØ³ Ù„Ø¯ÙŠÙƒ ØµÙ„Ø§Ø­ÙŠØ© Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø©')})
    
    try:
        result = []
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø­Ù…ÙŠØ© Ù…Ù† Django (ÙŠØ¬Ø¨ Ø§Ø³ØªØ¨Ø¹Ø§Ø¯Ù‡Ø§ Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø­Ø°Ù)
        protected_apps = [
            'admin',
            'auth',
            'contenttypes',
            'sessions',
            'messages',
            'staticfiles',
            'corsheaders',
            'rest_framework',
            'django_bootstrap5',
            'crispy_forms',
            'crispy_bootstrap5',
        ]
        
        # Ø¨Ù†Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø¹ÙƒØ³ÙŠØ©: model_label -> set(of dependent model labels)
        dep_map = {}
        all_models = []
        for app_config in apps.get_app_configs():
            # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø­Ù…ÙŠØ© Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø­Ø°Ù
            if app_config.name in protected_apps:
                continue
                
            for model in app_config.get_models():
                label = f"{app_config.name}.{model._meta.model_name}"
                dep_map[label] = set()
                all_models.append((app_config, model))

        # Ù…Ù„Ø¡ Ø§Ù„Ø®Ø±ÙŠØ·Ø©
        for app_config, model in all_models:
            for field in model._meta.get_fields():
                try:
                    if field.is_relation and (field.many_to_one or field.one_to_one) and field.related_model is not None:
                        rel = field.related_model
                        rel_label = f"{rel._meta.app_label}.{rel._meta.model_name}"
                        src_label = f"{app_config.name}.{model._meta.model_name}"
                        dep_map[rel_label].add(src_label)
                except Exception:
                    continue

        # Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù„ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬
        for app_config, model in all_models:
            try:
                # ØªØ®Ø·ÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ¯ÙŠØ± Ø¬Ø¯Ø§ÙˆÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (managed = False)
                if not model._meta.managed:
                    continue
                    
                label = f"{app_config.name}.{model._meta.model_name}"
                display = model._meta.verbose_name or label
                count = model.objects.count()
                dependents = sorted(list(dep_map.get(label, [])))
                # Ø§Ù…Ù† Ù„Ù„Ø­Ø°Ù Ø¥Ø°Ø§ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ§Ø¨Ø¹ÙˆÙ† (dependents) Ø£Ùˆ Ø§Ù„ØªÙˆØ§Ø¨Ø¹ ÙƒÙ„Ù‡Ø§ Ø¶Ù…Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø³ØªØ¨Ø¹Ø¯Ø©
                safe = len(dependents) == 0
                result.append({
                    'app_name': app_config.name,
                    'model_name': model._meta.model_name,
                    'label': label,
                    'display_name': str(display),
                    'record_count': count,
                    'dependents': dependents,
                    'safe_to_delete': safe
                })
            except Exception as e:
                logger.warning(f"ÙØ´Ù„ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {app_config.name}.{model}: {str(e)}")
                continue

        # Ø±ØªØ¨ Ø¨Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ØªÙ†Ø§Ø²Ù„ÙŠØ§Ù‹
        result.sort(key=lambda x: (-x['record_count'], x['label']))
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ø£Ù†Ø´Ø·Ø©
        log_audit(request.user, 'view', _('Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø­Ø°Ù - ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {} Ø¬Ø¯ÙˆÙ„').format(len(result)))
        
        return JsonResponse({'success': True, 'tables': result})
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ get_deletable_tables: {str(e)}")
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ø£Ù†Ø´Ø·Ø©
        log_audit(request.user, 'error', _('Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø­Ø°Ù: {}').format(str(e)))
        return JsonResponse({'success': False, 'error': _('Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„')})


@login_required
def delete_selected_tables(request):
    """Ù…Ø³Ø­ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© (data-only) Ø¨Ø¹Ø¯ ÙØ­Øµ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª.
    ÙŠØªÙˆÙ‚Ø¹ POST body 'tables' ÙƒÙ‚Ø§Ø¦Ù…Ø© Ù…Ù† labels ['app.model', ...] Ùˆ 'confirm' boolean.
    Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ÙÙŠ ØªÙ„Ùƒ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø¯Ø§Ø®Ù„ Ù…Ø¹Ø§Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø©ØŒ ÙˆÙŠÙØ³Ø¬Ù„ ÙƒÙ„ Ø¹Ù…Ù„ÙŠØ© ÙÙŠ AuditLog.
    """
    if request.method != 'POST':
        return JsonResponse({'success': False, 'error': 'Ø·Ø±ÙŠÙ‚Ø© Ø·Ù„Ø¨ ØºÙŠØ± ØµØ­ÙŠØ­Ø©'})

    # ÙØ­Øµ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ©
    if not request.user.has_perm('backup.can_delete_advanced_data'):
        # ØªØ³Ø¬ÙŠÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ ØºÙŠØ± Ø§Ù„Ù…Ø³Ù…ÙˆØ­
        log_audit(request.user, 'denied', _('Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØµÙˆÙ„ Ù…Ø±ÙÙˆØ¶Ø© Ù„Ø­Ø°Ù Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ - ØµÙ„Ø§Ø­ÙŠØ© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©'))
        return JsonResponse({'success': False, 'error': _('Ù„ÙŠØ³ Ù„Ø¯ÙŠÙƒ ØµÙ„Ø§Ø­ÙŠØ© Ù„Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')})

    try:
        payload = json.loads(request.body.decode('utf-8')) if request.body else {}
    except Exception:
        payload = request.POST.dict() if request.POST else {}

    tables = payload.get('tables') or payload.get('labels') or []
    confirm = payload.get('confirm') in [True, 'true', '1', 1, 'on']

    if not tables or not isinstance(tables, list):
        return JsonResponse({'success': False, 'error': 'ÙŠØ±Ø¬Ù‰ ØªØ­Ø¯ÙŠØ¯ Ø¬Ø¯Ø§ÙˆÙ„ Ù„Ù„Ø­Ø°Ù'})

    if not confirm:
        return JsonResponse({'success': False, 'error': 'ÙŠØ±Ø¬Ù‰ ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø­Ø°Ù (confirm=true)'})

    try:
        # Ø¨Ù†Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ¨Ø¹ÙŠØ© ÙƒÙ…Ø§ ÙÙŠ get_deletable_tables
        dep_map = {}
        model_map = {}
        for app_config in apps.get_app_configs():
            for model in app_config.get_models():
                label = f"{app_config.name}.{model._meta.model_name}"
                dep_map[label] = set()
                model_map[label] = model

        for label, model in list(model_map.items()):
            for field in model._meta.get_fields():
                try:
                    if field.is_relation and (field.many_to_one or field.one_to_one) and field.related_model is not None:
                        rel = field.related_model
                        rel_label = f"{rel._meta.app_label}.{rel._meta.model_name}"
                        src_label = label
                        if rel_label in dep_map:
                            dep_map[rel_label].add(src_label)
                except Exception:
                    continue

        # ÙˆØ³Ù‘Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù„ØªØ´Ù…Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø© (closure)
        selected_set = set([str(x) for x in tables])
        def add_deps(label):
            for dep in dep_map.get(label, set()):
                if dep not in selected_set:
                    selected_set.add(dep)
                    add_deps(dep)

        for t in list(selected_set):
            add_deps(t)

        # Ø¨Ø¹Ø¯ Ø§Ù„ØªÙˆØ³ÙŠØ¹ØŒ ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ ØªØ¨Ø¹ÙŠØ§Øª Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        cannot_delete = []
        for t in list(selected_set):
            dependents = dep_map.get(t, set())
            external = [d for d in dependents if d not in selected_set]
            if external:
                cannot_delete.append({'table': t, 'blocked_by': external})

        if cannot_delete:
            return JsonResponse({'success': False, 'error': 'Ø¨Ø¹Ø¶ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø°ÙÙ‡Ø§ Ø¨Ø³Ø¨Ø¨ ØªØ¨Ø¹ÙŠØ§Øª Ø®Ø§Ø±Ø¬ÙŠØ©', 'details': cannot_delete})

        # Ø§Ø­Ø³Ø¨ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø­Ø°Ù Ø¨Ø­ÙŠØ« ØªÙØ­Ø°Ù Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø£ÙˆÙ„Ø§Ù‹ (post-order)
        visited = set()
        delete_order = []
        def dfs(label):
            if label in visited:
                return
            visited.add(label)
            for dep in dep_map.get(label, set()):
                if dep in selected_set:
                    dfs(dep)
            delete_order.append(label)

        for label in list(selected_set):
            dfs(label)

    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ¨Ø¹ÙŠØ© Ø£Ùˆ Ø­Ø³Ø§Ø¨ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø­Ø°Ù: {str(e)}")
        return JsonResponse({'success': False, 'error': str(e)})

    # ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ø°Ù Ø¯Ø§Ø®Ù„ Ù…Ø¹Ø§Ù…Ù„Ø© ÙˆØ¨ØªØ±ØªÙŠØ¨ Ø¢Ù…Ù†
    deleted_stats = []
    audit_reassign_notifications = []
    try:
        with transaction.atomic():
            for t in delete_order:
                model = model_map.get(t)
                if model is None:
                    continue
                try:
                    # Special handling for User model: create or keep a fallback '__deleted_user__' user
                    UserModel = None
                    try:
                        from django.contrib.auth import get_user_model
                        UserModel = get_user_model()
                    except Exception:
                        UserModel = None

                    if UserModel is not None and getattr(model, '__name__', '').lower() == getattr(UserModel, '__name__', '').lower():
                        # ensure fallback exists
                        fallback_username = '__deleted_user__'
                        fallback = UserModel.objects.filter(username=fallback_username).first()
                        if not fallback:
                            # create minimal fallback user
                            fallback = UserModel.objects.create(username=fallback_username, is_active=False)

                        # reassign AuditLog.user entries that reference users we will delete to fallback
                        try:
                            user_ids = list(model.objects.exclude(pk=fallback.pk).values_list('pk', flat=True))
                            from core.models import AuditLog as _AuditLog
                            if user_ids:
                                _AuditLog.objects.filter(user_id__in=user_ids).update(user_id=fallback.pk)
                        except Exception as reassign_err:
                            logger.warning(f"Failed to reassign AuditLog.user before deleting users: {reassign_err}")

                        # notify front-end that we reassigned audit logs for this table
                        audit_reassign_notifications.append({'table': t, 'fallback': fallback.username, 'reassigned_count': len(user_ids)})

                        # delete all users except fallback
                        qs = model.objects.exclude(pk=fallback.pk)
                        count = qs.count()
                        qs.delete()
                        deleted_stats.append({'table': t, 'deleted': count})
                        from django.utils.translation import gettext as _
                        log_audit(request.user, 'delete', _('Deleted all records from table %(table)s - count: %(count)s') % {'table': t, 'count': count})
                        continue

                    # Default deletion path for other models
                    count = model.objects.all().count()
                    # Ø­Ø§ÙˆÙ„ Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„Ø§ØªØ› Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ FK Ù…Ø­Ù…ÙŠ ÙØ³ÙŠÙØ«Ø§Ø± ProtectedError Ø£Ùˆ Ù‚Ø¯ ÙŠØ­Ø¯Ø« IntegrityError
                    try:
                        model.objects.all().delete()
                    except Exception as del_exc:
                        from django.db import IntegrityError
                        if isinstance(del_exc, IntegrityError):
                            # Special retry logic for User model: try to reassign AuditLog.user references then retry
                            try:
                                from django.contrib.auth import get_user_model
                                UserModelLocal = get_user_model()
                            except Exception:
                                UserModelLocal = None

                            if UserModelLocal is not None and getattr(model, '__name__', '').lower() == getattr(UserModelLocal, '__name__', '').lower():
                                # perform reassignment of AuditLog entries to fallback
                                try:
                                    fallback_username = '__deleted_user__'
                                    fallback = UserModelLocal.objects.filter(username=fallback_username).first()
                                    if not fallback:
                                        fallback = UserModelLocal.objects.create(username=fallback_username, is_active=False)
                                    user_ids = list(model.objects.exclude(pk=fallback.pk).values_list('pk', flat=True))
                                    from core.models import AuditLog as _AuditLog
                                    if user_ids:
                                        _AuditLog.objects.filter(user_id__in=user_ids).update(user_id=fallback.pk)
                                    # retry delete
                                    model.objects.exclude(pk=fallback.pk).delete()
                                except Exception as reassign_err:
                                    logger.error(f"Failed to reassign AuditLog on IntegrityError: {reassign_err}")
                                    raise del_exc
                            else:
                                raise del_exc

                    deleted_stats.append({'table': t, 'deleted': count})
                    from django.utils.translation import gettext as _
                    log_audit(request.user, 'delete', _('Deleted all records from table %(table)s - count: %(count)s') % {'table': t, 'count': count})
                except ProtectedError as p_err:
                    # Ø¬Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ ÙŠÙ…Ù†Ø¹ Ø§Ù„Ø­Ø°Ù Ø¨Ø³Ø¨Ø¨ ProtectedError
                    blockers = []
                    try:
                        # ProtectedError.args may include a list/queryset of blocking objects
                        for item in getattr(p_err, 'protected_objects', []) or []:
                            try:
                                blockers.append(str(item))
                            except Exception:
                                blockers.append(repr(item))
                    except Exception:
                        blockers = [str(p_err)]
                    logger.warning(f"ProtectedError deleting {t}: {blockers}")
                    return JsonResponse({'success': False, 'error': 'ProtectedError', 'details': {'table': t, 'blocked_by_instances': blockers}})

        return JsonResponse({'success': True, 'deleted': deleted_stats, 'audit_reassign_notifications': audit_reassign_notifications})
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ delete_selected_tables: {str(e)}")
        return JsonResponse({'success': False, 'error': str(e)})


def set_restore_progress_data(data):
    """ØªØ­Ø¯ÙŠØ« Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ‚Ø¯Ù… Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© ÙÙŠ cache"""
    import time
    current_time = time.time()
    cache.set('restore_progress', data, timeout=3600)
    cache.set('restore_last_update', current_time, timeout=3600)
    if 'percentage' in data:
        cache.set('restore_last_percentage', data['percentage'], timeout=3600)


class BackupRestoreView(LoginRequiredMixin, TemplateView):
    """ØµÙØ­Ø© Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙˆØ§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©"""
    template_name = 'backup/backup_restore.html'
    
    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        backup_dir = os.path.join(settings.MEDIA_ROOT, 'backups')
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        
        # Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        backups = []
        for filename in os.listdir(backup_dir):
            if filename.endswith('.json') or filename.endswith('.xlsx'):
                filepath = os.path.join(backup_dir, filename)
                try:
                    stat = os.stat(filepath)
                    file_type = 'XLSX' if filename.endswith('.xlsx') else 'JSON'
                    backups.append({
                        'filename': filename,
                        'size': filesizeformat(stat.st_size),
                        'created_at': dt_module.fromtimestamp(stat.st_mtime),
                        'path': filepath,
                        'type': file_type
                    })
                except (OSError, IOError):
                    continue

        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†Ø³Ø® Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
        backups.sort(key=lambda x: x['created_at'], reverse=True)

        context['backups'] = backups
        context['is_superuser'] = self.request.user.is_superuser
        return context


@login_required
def get_backup_progress(request):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© ØªÙ‚Ø¯Ù… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
    if not request.user.is_authenticated:
        return JsonResponse({
            'success': False,
            'error': 'ÙŠØ¬Ø¨ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹',
            'progress': None
        }, status=401)
    
    progress_data = get_backup_progress_data()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© ÙˆØ­Ø°ÙÙ‡Ø§ Ø¥Ø°Ø§ Ù…Ø± ÙˆÙ‚Øª Ø·ÙˆÙŠÙ„
    if progress_data.get('is_running', False):
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ØªØ¹Ù…Ù„ Ù„Ø£ÙƒØ«Ø± Ù…Ù† 30 Ø¯Ù‚ÙŠÙ‚Ø©ØŒ Ù‚Ù… Ø¨Ø¥Ù„ØºØ§Ø¦Ù‡Ø§
        import time
        current_time = time.time()
        
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ù„Ù…Ø¯Ø© 10 Ø¯Ù‚Ø§Ø¦Ù‚ØŒ Ø§Ø¹ØªØ¨Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ø¹Ù„Ù‚Ø©
        last_update_key = 'backup_last_update'
        last_update = cache.get(last_update_key, current_time)
        
        if current_time - last_update > 600:  # 10 Ø¯Ù‚Ø§Ø¦Ù‚
            # Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ø¹Ù„Ù‚Ø©ØŒ Ù‚Ù… Ø¨Ø¥Ù„ØºØ§Ø¦Ù‡Ø§
            cache.delete('backup_progress')
            cache.delete(last_update_key)
            
            log_audit(request.user, 'delete', 'ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹')
    
    return JsonResponse({
        'success': True,
        'progress': progress_data
    })


@login_required
def clear_backup_cache(request):
    """Ù…Ø³Ø­ ÙƒØ§Ø´ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"""
    if request.method != 'POST':
        return JsonResponse({
            'success': False,
            'error': 'Ø·Ø±ÙŠÙ‚Ø© Ø·Ù„Ø¨ ØºÙŠØ± ØµØ­ÙŠØ­Ø©'
        })
    
    try:
        cache.delete('backup_progress')
        cache.delete('backup_last_update')
        
        log_audit(request.user, 'delete', 'ØªÙ… Ù…Ø³Ø­ ÙƒØ§Ø´ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙŠØ¯ÙˆÙŠØ§Ù‹')
        
        return JsonResponse({
            'success': True,
            'message': 'ØªÙ… Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´ Ø¨Ù†Ø¬Ø§Ø­'
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„ÙƒØ§Ø´: {str(e)}")
        return JsonResponse({
            'success': False,
            'error': str(e)
        })


def get_backup_tables_info():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙØµÙ„Ø© Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    tables_info = []
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø³ØªØ«Ù†Ø§Ø© Ù…Ù† Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ (ØªØ·Ø¨ÙŠÙ‚Ø§Øª Django Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙ‚Ø·)
    excluded_apps = [
        'django.contrib.admin',
        'django.contrib.contenttypes', 
        'django.contrib.sessions',
        'django.contrib.messages',
        'django.contrib.staticfiles',
        'corsheaders',
        'rest_framework',
        'django_bootstrap5',
        'crispy_forms',
        'crispy_bootstrap5',
    ]
    
    try:
        for app_config in apps.get_app_configs():
            if app_config.name in excluded_apps:
                continue
                
            for model in app_config.get_models():
                # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ Ù„Ø§ ØªÙ†Ø´Ø¦ Ø¬Ø¯Ø§ÙˆÙ„ (managed = False)
                if getattr(model._meta, 'managed', True) is False:
                    continue
                    
                try:
                    record_count = model.objects.count()
                    tables_info.append({
                        'app_name': app_config.name,
                        'model_name': model._meta.model_name,
                        'display_name': model._meta.verbose_name or f"{app_config.verbose_name} - {model._meta.model_name}",
                        'record_count': record_count,
                        'status': 'pending',
                        'progress': 0,
                        'actual_records': 0,
                        'error': None
                    })
                except Exception as e:
                    # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ØªØ³Ø¨Ø¨ Ø£Ø®Ø·Ø§Ø¡ (Ù…Ø«Ù„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©)
                    logger.warning(f"ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model._meta.model_name} Ø¨Ø³Ø¨Ø¨ Ø®Ø·Ø£: {str(e)}")
                    continue
        
        return tables_info
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {str(e)}")
        return []


@login_required
def get_backup_tables(request):
    """API Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„"""
    try:
        if not request.user.is_authenticated:
            return JsonResponse({
                'success': False,
                'error': 'ÙŠØ¬Ø¨ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹'
            }, status=401)
        
        tables_info = get_backup_tables_info()
        return JsonResponse({
            'success': True,
            'tables': tables_info,
            'total_tables': len(tables_info),
            'total_records': sum(table['record_count'] for table in tables_info)
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {str(e)}")
        
        log_audit(request.user, 'error', f'Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {str(e)}')
        
        return JsonResponse({
            'success': False,
            'error': str(e)
        })


def perform_backup_task(user, timestamp, filename, filepath, format_type='json'):
    """ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„ Ù…Ø¹ ØªØªØ¨Ø¹ Ù…ÙØµÙ„"""
    
    logger.info(f"ğŸ¯ Ø¯Ø®ÙˆÙ„ perform_backup_task: user={user.username}, filename={filename}, format={format_type}")
    
    try:
        log_audit(user, 'create', f'Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {filename} - Ø§Ù„Ù†ÙˆØ¹: {format_type.upper()}')
        
        # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
        progress_data = {
            'is_running': True,
            'status': 'starting',
            'error': None,
            'percentage': 0,
            'current_table': 'Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ...',
            'processed_tables': 0,
            'total_tables': 0,
            'processed_records': 0,
            'total_records': 0,
            'estimated_time': 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨...',
            'tables_status': []
        }
        set_backup_progress_data(progress_data)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        progress_data['current_table'] = 'ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...'
        progress_data['status'] = 'analyzing'
        set_backup_progress_data(progress_data)
        
        tables_info = get_backup_tables_info()
        total_tables = len(tables_info)
        total_records = sum(table['record_count'] for table in tables_info)
        
        # ØªØ­Ø¯ÙŠØ« Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        for table in tables_info:
            table['status'] = 'pending'
            table['progress'] = 0
            table['actual_records'] = 0
            table['error'] = None
        
        progress_data.update({
            'status': 'preparing',
            'current_table': f'ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {total_tables} Ø¬Ø¯ÙˆÙ„ Ø¨Ø¥Ø¬Ù…Ø§Ù„ÙŠ {total_records} Ø³Ø¬Ù„',
            'total_tables': total_tables,
            'total_records': total_records,
            'tables_status': tables_info,
            'percentage': 5
        })
        set_backup_progress_data(progress_data)
        
        time.sleep(2)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        backup_content = {
            'metadata': {
                'backup_name': f'Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© {timestamp}',
                'created_at': timezone.now().isoformat(),
                'created_by': user.username,
                'system_version': '1.0',
                'total_tables': total_tables,
                'total_records': total_records,
                'format': format_type.upper(),
                'description': 'Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙƒØ§Ù…Ù„Ø© Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙØµÙŠÙ„ÙŠØ©'
            },
            'data': {}
        }

        # ØªØ¶Ù…ÙŠÙ† Ù‚Ø§Ø¦Ù…Ø© Ø¨Ù…Ù„ÙØ§Øª Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ø§Ù„Ù…Ù‡Ù…Ø© (Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØµÙˆØ± Ø§Ù„Ø®Ù„ÙÙŠØ©) Ø¶Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        try:
            media_files = []
            system_media_dir = os.path.join(settings.MEDIA_ROOT, 'system')
            if os.path.exists(system_media_dir):
                for root, dirs, files in os.walk(system_media_dir):
                    for fname in files:
                        fpath = os.path.join(root, fname)
                        rel = os.path.relpath(fpath, settings.MEDIA_ROOT)
                        media_files.append(rel.replace('\\', '/'))
            backup_content['media_files'] = media_files
        except Exception as e:
            logger.warning(f"ÙØ´Ù„ ÙÙŠ Ø­ØµØ± Ù…Ù„ÙØ§Øª Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ù„Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {str(e)}")
        
        # ØªØ¶Ù…ÙŠÙ† Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ±Ø¬Ù…Ø©
        try:
            locale_files = []
            locale_dir = os.path.join(settings.BASE_DIR, 'locale')
            if os.path.exists(locale_dir):
                for root, dirs, files in os.walk(locale_dir):
                    for fname in files:
                        if fname.endswith('.po') or fname.endswith('.mo'):
                            fpath = os.path.join(root, fname)
                            rel = os.path.relpath(fpath, settings.BASE_DIR)
                            locale_files.append(rel.replace('\\', '/'))
            backup_content['locale_files'] = locale_files
        except Exception as e:
            logger.warning(f"ÙØ´Ù„ ÙÙŠ Ø­ØµØ± Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© Ù„Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {str(e)}")
        
        # Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ØªØªØ¨Ø¹
        processed_tables = 0
        processed_records = 0
        start_time = time.time()
        
        progress_data = get_backup_progress_data()
        progress_data.update({
            'status': 'processing',
            'current_table': 'Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„...',
            'percentage': 10
        })
        set_backup_progress_data(progress_data)
        
        # Ù†Ø³Ø® Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
        for table_index, table_info in enumerate(tables_info):
            app_name = table_info['app_name']
            model_name = table_info['model_name']
            display_name = table_info['display_name']
            expected_records = table_info['record_count']
            
            try:
                progress_data = get_backup_progress_data()
                tables_status = progress_data.get('tables_status', [])
                
                if table_index < len(tables_status):
                    tables_status[table_index]['status'] = 'processing'
                    tables_status[table_index]['progress'] = 0
                
                progress_data.update({
                    'current_table': f'Ù…Ø¹Ø§Ù„Ø¬Ø© {display_name}...',
                    'tables_status': tables_status
                })
                set_backup_progress_data(progress_data)
                
                # ØªØ³Ø¬ÙŠÙ„ Ø¨Ø¯Ø§ÙŠØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„
                log_audit(user, 'create', f'Ø¨Ø¯Ø¡ Ù†Ø³Ø® Ø§Ù„Ø¬Ø¯ÙˆÙ„: {display_name} ({expected_records} Ø³Ø¬Ù„ Ù…ØªÙˆÙ‚Ø¹)')
                
                # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                app = apps.get_app_config(app_name)
                model = app.get_model(model_name)
                
                if app_name not in backup_content['data']:
                    backup_content['data'][app_name] = {}
                
                # Ù†Ø³Ø® Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø´ÙƒØ§Ù„ÙŠØ©
                queryset = model.objects.all()
                
                # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø°Ø§Øª Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª
                if hasattr(model, '_meta'):
                    # Ø¥Ø¶Ø§ÙØ© select_related Ù„Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø£Ø¬Ù†Ø¨ÙŠØ© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©
                    foreign_keys = [f.name for f in model._meta.fields if hasattr(f, 'related_model') and f.related_model]
                    if foreign_keys:
                        queryset = queryset.select_related(*foreign_keys)
                    
                    # Ø¥Ø¶Ø§ÙØ© prefetch_related Ù„Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø¹ÙƒØ³ÙŠØ© Ø§Ù„Ù…Ù‡Ù…Ø©
                    reverse_relations = []
                    for related in model._meta.related_objects:
                        if related.one_to_many or related.many_to_many:
                            reverse_relations.append(related.get_accessor_name())
                    if reverse_relations:
                        queryset = queryset.prefetch_related(*reverse_relations)
                
                actual_records = queryset.count()
                
                if actual_records > 0:
                    # Ø²ÙŠØ§Ø¯Ø© Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Ù…Ù† 10 Ø¥Ù„Ù‰ 50 Ø¬Ø²Ø¡)
                    chunk_size = max(100, actual_records // 50)  # Ø­Ø¯ Ø£Ø¯Ù†Ù‰ 100 Ø³Ø¬Ù„ Ù„ÙƒÙ„ Ø¬Ø²Ø¡
                    processed_in_table = 0
                    
                    all_data = []
                    for chunk_start in range(0, actual_records, chunk_size):
                        chunk_end = min(chunk_start + chunk_size, actual_records)
                        chunk_queryset = queryset[chunk_start:chunk_end]
                        
                        try:
                            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ø¹Ø§Ø¯ÙŠ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…ØªØ§Ø­Ø©
                            chunk_data = serializers.serialize('json', chunk_queryset)
                            serialized_data = json.loads(chunk_data)
                            
                            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©
                            cleaned_data = []
                            for item in serialized_data:
                                if 'fields' in item:
                                    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ© Ø£Ùˆ ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© - ØªÙ… Ø¥Ø²Ø§Ù„Ø© ÙÙ„ØªØ±Ø© is_service
                                    pass
                                cleaned_data.append(item)
                            
                            all_data.extend(cleaned_data)
                            
                        except Exception as serialization_error:
                            # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„ØªØ³Ù„Ø³Ù„ØŒ Ù†Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ÙØ±Ø¯ÙŠØ§Ù‹
                            logger.warning(f"ÙØ´Ù„ ØªØ³Ù„Ø³Ù„ chunk ÙÙŠ {display_name}: {str(serialization_error)}")
                            
                            for record in chunk_queryset:
                                try:
                                    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ³Ù„Ø³Ù„ Ø³Ø¬Ù„ ÙˆØ§Ø­Ø¯
                                    single_data = serializers.serialize('json', [record])
                                    serialized_record = json.loads(single_data)
                                    
                                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©
                                    for item in serialized_record:
                                        # ØªÙ… Ø¥Ø²Ø§Ù„Ø© ÙÙ„ØªØ±Ø© is_service - Ø§Ù„Ø­Ù‚Ù„ Ù„Ù… ÙŠØ¹Ø¯ Ù…ÙˆØ¬ÙˆØ¯
                                        pass
                                    
                                    all_data.extend(serialized_record)
                                    
                                except Exception as single_error:
                                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ§Ù„ÙØ©
                                    logger.warning(f"ÙØ´Ù„ ÙÙŠ ØªØ³Ù„Ø³Ù„ Ø³Ø¬Ù„ {record.pk} ÙÙŠ {display_name}: {str(single_error)}")
                                    
                                    # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø¢Ù…Ù† ÙŠØ¯ÙˆÙŠØ§Ù‹
                                    safe_record = {
                                        'model': f"{app_name}.{model_name}",
                                        'pk': record.pk,
                                        'fields': {}
                                    }
                                    
                                    # Ù†Ø³Ø® Ø§Ù„Ø­Ù‚ÙˆÙ„ Ù…Ø¹ ØªØ¬Ù†Ø¨ Ø§Ù„Ù…Ø´Ø§ÙƒÙ„
                                    for field in model._meta.fields:
                                        field_name = field.name
                                        
                                        # ØªÙ… Ø¥Ø²Ø§Ù„Ø© ÙÙ„ØªØ±Ø© is_service - Ø§Ù„Ø­Ù‚Ù„ Ù„Ù… ÙŠØ¹Ø¯ Ù…ÙˆØ¬ÙˆØ¯
                                            
                                        try:
                                            value = getattr(record, field_name)
                                            
                                            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ø´ÙƒØ§Ù„ÙŠØ©
                                            if hasattr(field, 'upload_to'):  # Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„ØµÙˆØ±
                                                if value and hasattr(value, 'name'):
                                                    safe_record['fields'][field_name] = value.name
                                                else:
                                                    safe_record['fields'][field_name] = None
                                            elif hasattr(value, 'isoformat'):  # Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ®
                                                safe_record['fields'][field_name] = value.isoformat()
                                            elif value is None:
                                                safe_record['fields'][field_name] = None
                                            else:
                                                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚ÙŠÙ…Ø© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ³Ù„Ø³Ù„
                                                try:
                                                    json.dumps(value)
                                                    safe_record['fields'][field_name] = value
                                                except (TypeError, ValueError):
                                                    safe_record['fields'][field_name] = str(value)
                                                    
                                        except Exception as field_error:
                                            logger.warning(f"ÙØ´Ù„ ÙÙŠ Ø­Ù‚Ù„ {field_name} Ù„Ù„Ø³Ø¬Ù„ {record.pk}: {str(field_error)}")
                                            safe_record['fields'][field_name] = None
                                    
                                    all_data.append(safe_record)
                                    log_audit(user, 'warning', f'ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ø³Ø¬Ù„ ØªØ§Ù„Ù: {display_name} - Ø§Ù„Ù…Ø¹Ø±Ù: {record.pk}')
                        
                        processed_in_table = chunk_end
                        table_progress = int((processed_in_table / actual_records) * 100)
                        
                        progress_data = get_backup_progress_data()
                        tables_status = progress_data.get('tables_status', [])
                        if table_index < len(tables_status):
                            tables_status[table_index]['progress'] = table_progress
                        
                        progress_data.update({
                            'current_table': f'{display_name}: {processed_in_table}/{actual_records} ({table_progress}%)',
                            'tables_status': tables_status
                        })
                        set_backup_progress_data(progress_data)
                        
                        time.sleep(0.3)
                    
                    backup_content['data'][app_name][model_name] = all_data
                else:
                    backup_content['data'][app_name][model_name] = []
                
                processed_records += actual_records
                processed_tables += 1
                
                progress_data = get_backup_progress_data()
                tables_status = progress_data.get('tables_status', [])
                if table_index < len(tables_status):
                    tables_status[table_index]['status'] = 'completed'
                    tables_status[table_index]['progress'] = 100
                    tables_status[table_index]['actual_records'] = actual_records
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ
                elapsed_time = time.time() - start_time
                if processed_tables > 0:
                    avg_time_per_table = elapsed_time / processed_tables
                    remaining_tables = total_tables - processed_tables
                    estimated_remaining = avg_time_per_table * remaining_tables
                    estimated_time = f"{int(estimated_remaining)} Ø«Ø§Ù†ÙŠØ© Ù…ØªØ¨Ù‚ÙŠØ© ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹"
                else:
                    estimated_time = "Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ..."
                
                overall_progress = 10 + int(((processed_tables / total_tables) * 80))
                progress_data.update({
                    'processed_tables': processed_tables,
                    'processed_records': processed_records,
                    'percentage': overall_progress,
                    'tables_status': tables_status,
                    'estimated_time': estimated_time,
                    'current_table': f'Ø§ÙƒØªÙ…Ù„ {display_name} âœ… ({actual_records} Ø³Ø¬Ù„)'
                })
                set_backup_progress_data(progress_data)
                
                log_audit(user, 'update', f'Ø§ÙƒØªÙ…Ù„ Ù†Ø³Ø® Ø§Ù„Ø¬Ø¯ÙˆÙ„: {display_name} - ØªÙ… Ù†Ø³Ø® {actual_records} Ø³Ø¬Ù„')
                
                time.sleep(0.5)
                
            except Exception as e:
                error_msg = f"ØªØ¹Ø°Ø± Ù†Ø³Ø® Ø¬Ø¯ÙˆÙ„ {display_name}: {str(e)}"
                logger.error(error_msg)
                
                # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£
                log_audit(user, 'error', error_msg)
                
                progress_data = get_backup_progress_data()
                tables_status = progress_data.get('tables_status', [])
                if table_index < len(tables_status):
                    tables_status[table_index]['status'] = 'error'
                    tables_status[table_index]['error'] = str(e)
                    tables_status[table_index]['progress'] = 0
                
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø±ØºÙ… Ø§Ù„Ø®Ø·Ø£
                processed_tables += 1
                overall_progress = 10 + int(((processed_tables / total_tables) * 80))
                
                progress_data.update({
                    'processed_tables': processed_tables,
                    'percentage': overall_progress,
                    'tables_status': tables_status,
                    'current_table': f'âš ï¸ ÙØ´Ù„ ÙÙŠ {display_name}: {str(e)[:50]}...',
                    'errors': progress_data.get('errors', []) + [error_msg]
                })
                set_backup_progress_data(progress_data)
                
                # Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠ
                time.sleep(1)
                continue
                if table_index < len(tables_status):
                    tables_status[table_index]['status'] = 'error'
                    tables_status[table_index]['error'] = str(e)
                
                progress_data.update({
                    'tables_status': tables_status,
                    'current_table': f'Ø®Ø·Ø£ ÙÙŠ {display_name}: {str(e)}'
                })
                set_backup_progress_data(progress_data)
                
                if AUDIT_AVAILABLE:
                    try:
                        AuditLog.objects.create(
                            user=user,
                            action='backup_table_error',
                            details=f'Ø®Ø·Ø£ ÙÙŠ Ù†Ø³Ø® Ø§Ù„Ø¬Ø¯ÙˆÙ„: {display_name} - {str(e)}'
                        )
                    except Exception:
                        pass
                
                processed_tables += 1
                time.sleep(1)
                continue
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        progress_data = get_backup_progress_data()
        progress_data.update({
            'current_table': 'Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ...',
            'status': 'saving',
            'percentage': 95,
            'estimated_time': 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø­ÙØ¸...'
        })
        set_backup_progress_data(progress_data)
        
        try:
            # Ø­ÙØ¸ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            if format_type.lower() == 'xlsx':
                if AUDIT_AVAILABLE:
                    try:
                        AuditLog.objects.create(
                            user=user,
                            action='backup_saving_xlsx',
                            details=f'Ø¨Ø¯Ø¡ Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¨ØµÙŠØºØ© XLSX: {filename}'
                        )
                    except Exception:
                        pass
                save_backup_as_xlsx(backup_content, filepath)
            else:
                if AUDIT_AVAILABLE:
                    try:
                        AuditLog.objects.create(
                            user=user,
                            action='backup_saving_json',
                            details=f'Ø¨Ø¯Ø¡ Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¨ØµÙŠØºØ© JSON: {filename}'
                        )
                    except Exception:
                        pass
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(backup_content, f, ensure_ascii=False, indent=2)
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            if not os.path.exists(filepath):
                raise Exception(f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù: {filepath}")
            
            file_size = os.path.getsize(filepath)
            if file_size == 0:
                raise Exception(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ÙØ§Ø±Øº: {filepath}")
                
            logger.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­: {filepath} - Ø§Ù„Ø­Ø¬Ù…: {file_size} Ø¨Ø§ÙŠØª")
            
        except Exception as save_error:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {str(save_error)}")
            
            if AUDIT_AVAILABLE:
                try:
                    AuditLog.objects.create(
                        user=user,
                        action='backup_save_error',
                        details=f'Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {filename} - Ø®Ø·Ø£: {str(save_error)}'
                    )
                except Exception:
                    pass
            
            raise save_error
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù†Ø§Ø¬Ø­Ø©
        progress_data.update({
            'status': 'completed',
            'current_table': 'ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ù†Ø¬Ø§Ø­! âœ…',
            'percentage': 100,
            'is_running': False,
            'estimated_time': 'Ø§ÙƒØªÙ…Ù„'
        })
        set_backup_progress_data(progress_data)
        
        # Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        empty_tables = 0
        non_empty_tables = 0
        for table_info in tables_info:
            if table_info['record_count'] == 0:
                empty_tables += 1
            else:
                non_empty_tables += 1
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ø´Ø§Ø· Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        details = f'ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­: {filename} - Ø§Ù„Ù†ÙˆØ¹: {format_type.upper()} - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {total_tables} (ÙØ§Ø±ØºØ©: {empty_tables}, ØªØ­ØªÙˆÙŠ Ø¨ÙŠØ§Ù†Ø§Øª: {non_empty_tables}) - Ø§Ù„Ø³Ø¬Ù„Ø§Øª: {processed_records}'
        log_audit(user, 'create', details)
        
        logger.info(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­: {filename}")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒØ§Ø´ Ø¨Ø¹Ø¯ ÙØªØ±Ø© Ù‚ØµÙŠØ±Ø© Ù„Ù„Ø³Ù…Ø§Ø­ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø¨Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        def cleanup_cache():
            time.sleep(10)  # Ø§Ù†ØªØ¸Ø§Ø± 10 Ø«ÙˆØ§Ù†ÙŠ
            cache.delete('backup_progress')
            cache.delete('backup_last_update')
        
        threading.Thread(target=cleanup_cache, daemon=True).start()
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {str(e)}")
        
        progress_data = get_backup_progress_data()
        progress_data.update({
            'status': 'error',
            'error': str(e),
            'is_running': False,
            'current_table': f'Ø®Ø·Ø£: {str(e)}'
        })
        set_backup_progress_data(progress_data)
        
        log_audit(user, 'error', f'ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {filename} - Ø®Ø·Ø£: {str(e)}')
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒØ§Ø´ Ø¨Ø¹Ø¯ ÙØªØ±Ø© Ù‚ØµÙŠØ±Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø®Ø·Ø£ Ø£ÙŠØ¶Ø§Ù‹
        def cleanup_cache_error():
            time.sleep(30)  # Ø§Ù†ØªØ¸Ø§Ø± 30 Ø«Ø§Ù†ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø®Ø·Ø£
            cache.delete('backup_progress')
            cache.delete('backup_last_update')
        
        threading.Thread(target=cleanup_cache_error, daemon=True).start()
        threading.Thread(target=cleanup_cache_error, daemon=True).start()
        
        raise e


def clean_sheet_name(name):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù…Ù„ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Excel"""
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù ØºÙŠØ± Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© ÙÙŠ Excel
    invalid_chars = ['\\', '/', '?', '*', '[', ']', ':', '\'']
    cleaned_name = str(name) if name else ''
    for char in invalid_chars:
        cleaned_name = cleaned_name.replace(char, '_')
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù†Ù‚Ø§Ø· (Ù‚Ø¯ ØªØªØ³Ø¨Ø¨ ÙÙŠ Ù…Ø´Ø§ÙƒÙ„)
    cleaned_name = cleaned_name.replace('.', '_')
    
    # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø£Ø­Ø±Ù Ø®Ø§ØµØ© Ø£Ø®Ø±Ù‰ Ù‚Ø¯ ØªØ³Ø¨Ø¨ Ù…Ø´Ø§ÙƒÙ„
    cleaned_name = ''.join(c if c.isalnum() or c in '_- ' else '_' for c in cleaned_name)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø¨Ù€ underscore ÙˆØ§Ø­Ø¯
    cleaned_name = '_'.join(cleaned_name.split())
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰ (31 Ø­Ø±Ù Ù‡Ùˆ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù€ Excel)
    if len(cleaned_name) > 31:
        cleaned_name = cleaned_name[:31]
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø§Ø³Ù… Ù„ÙŠØ³ ÙØ§Ø±ØºØ§Ù‹ Ø£Ùˆ ÙŠØ¨Ø¯Ø£ Ø¨Ø±Ù‚Ù…
    if not cleaned_name or cleaned_name.isspace() or cleaned_name[0].isdigit():
        cleaned_name = "Sheet_" + cleaned_name[:25] if cleaned_name else "Sheet1"
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ø±Ø© Ø£Ø®ÙŠØ±Ø© Ù…Ù† Ø§Ù„Ø·ÙˆÙ„
    if len(cleaned_name) > 31:
        cleaned_name = cleaned_name[:31]
    
    return cleaned_name


def save_backup_as_xlsx(backup_content, filepath):
    """Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙƒÙ…Ù„Ù Excel"""
    try:
        logger.info(f"Ø¨Ø¯Ø¡ Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙƒÙ€ XLSX: {filepath}")
        
        workbook = Workbook()
        
        # Ø­Ø°Ù Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        workbook.remove(workbook.active)
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ±Ù‚Ø© Ù„Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
        info_sheet = workbook.create_sheet(title="Backup Info")
        metadata = backup_content.get('metadata', {})
        
        info_sheet['A1'] = 'Backup Name'
        info_sheet['B1'] = metadata.get('backup_name', '')
        info_sheet['A2'] = 'Created At'
        info_sheet['B2'] = metadata.get('created_at', '')
        info_sheet['A3'] = 'Created By'
        info_sheet['B3'] = metadata.get('created_by', '')
        info_sheet['A4'] = 'Total Tables'
        info_sheet['B4'] = metadata.get('total_tables', 0)
        info_sheet['A5'] = 'Total Records'
        info_sheet['B5'] = metadata.get('total_records', 0)
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ±Ù‚Ø© Ù„ÙƒÙ„ ØªØ·Ø¨ÙŠÙ‚
        data = backup_content.get('data', {})
        sheet_count = 0
        used_sheet_names = set()  # ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
        
        for app_name, app_data in data.items():
            for model_name, model_data in app_data.items():
                if isinstance(model_data, list):  # Ø¥Ø²Ø§Ù„Ø© Ø´Ø±Ø· Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© ØºÙŠØ± ÙØ§Ø±ØºØ©
                    try:
                        # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù…Ù„ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Excel
                        raw_sheet_name = f"{app_name}_{model_name}"
                        sheet_name = clean_sheet_name(raw_sheet_name)
                        
                        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ØªÙƒØ±Ø§Ø± Ø§Ù„Ø§Ø³Ù…
                        original_name = sheet_name
                        counter = 1
                        while sheet_name in used_sheet_names:
                            counter_suffix = f"_{counter}"
                            max_length = 31 - len(counter_suffix)
                            if len(original_name) > max_length:
                                sheet_name = f"{original_name[:max_length]}{counter_suffix}"
                            else:
                                sheet_name = f"{original_name}{counter_suffix}"
                            counter += 1
                        
                        used_sheet_names.add(sheet_name)
                        sheet = workbook.create_sheet(title=sheet_name)
                        sheet_count += 1
                        
                        if len(model_data) > 0:
                            # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø±Ø¤ÙˆØ³
                            first_record = model_data[0]
                            if isinstance(first_record, dict) and 'fields' in first_record:
                                fields = first_record.get('fields', {})
                                
                                # ÙÙ„ØªØ±Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ©
                                filtered_fields = {}
                                for field_name, field_value in fields.items():
                                    # ØªÙ… Ø¥Ø²Ø§Ù„Ø© ÙÙ„ØªØ±Ø© is_service - Ø§Ù„Ø­Ù‚Ù„ Ù„Ù… ÙŠØ¹Ø¯ Ù…ÙˆØ¬ÙˆØ¯
                                    filtered_fields[field_name] = field_value
                                
                                headers = ['ID'] + list(filtered_fields.keys())
                                for col, header in enumerate(headers, 1):
                                    # ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯
                                    clean_header = str(header) if header else f'Column_{col}'
                                    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ© Ù…Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                                    clean_header = ''.join(c if c.isalnum() or c in ' _-' else '_' for c in clean_header)
                                    if len(clean_header) > 255:  # Ø­Ø¯ Excel Ù„Ù„Ø£Ø¹Ù…Ø¯Ø©
                                        clean_header = clean_header[:252] + "..."
                                    sheet.cell(row=1, column=col, value=clean_header)
                                
                                # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                                for row_idx, record in enumerate(model_data, 2):
                                    if isinstance(record, dict):
                                        sheet.cell(row=row_idx, column=1, value=record.get('pk', ''))
                                        record_fields = record.get('fields', {})
                                        
                                        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø­Ø°ÙˆÙØ© Ù‚Ø¨Ù„ Ø§Ù„ÙƒØªØ§Ø¨Ø©
                                        filtered_record_fields = {}
                                        for field_name, field_value in record_fields.items():
                                            # ØªÙ… Ø¥Ø²Ø§Ù„Ø© ÙÙ„ØªØ±Ø© is_service - Ø§Ù„Ø­Ù‚Ù„ Ù„Ù… ÙŠØ¹Ø¯ Ù…ÙˆØ¬ÙˆØ¯
                                            filtered_record_fields[field_name] = field_value
                                        
                                        for col_idx, (field_name, field_value) in enumerate(filtered_record_fields.items(), 2):
                                            try:
                                                if field_value is None:
                                                    cell_value = ''
                                                elif isinstance(field_value, (str, int, float, bool)):
                                                    cell_value = str(field_value)
                                                else:
                                                    cell_value = str(field_value)
                                                
                                                # ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ Excel
                                                if len(cell_value) > 32767:
                                                    cell_value = cell_value[:32760] + "..."
                                                    
                                                # ØªØ¬Ù†Ø¨ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ© Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Excel
                                                if cell_value and any(ord(char) < 32 for char in cell_value if char != '\t' and char != '\n' and char != '\r'):
                                                    cell_value = ''.join(char if ord(char) >= 32 or char in '\t\n\r' else '?' for char in cell_value)
                                                    
                                                sheet.cell(row=row_idx, column=col_idx, value=cell_value)
                                            except Exception as cell_error:
                                                logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø®Ù„ÙŠØ© {field_name}: {str(cell_error)}")
                                                sheet.cell(row=row_idx, column=col_idx, value='Error')
                        else:
                            # Ø¥Ø¶Ø§ÙØ© Ø±Ø£Ø³ Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ©
                            sheet.cell(row=1, column=1, value='ID')
                            sheet.cell(row=1, column=2, value='Empty Table')
                            
                        logger.debug(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù…Ù„: {sheet_name} Ù…Ø¹ {len(model_data)} Ø³Ø¬Ù„")
                    
                    except Exception as e:
                        logger.warning(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù…Ù„ {app_name}_{model_name}: {str(e)}")
                        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ audit log Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
                        try:
                            from core.models import AuditLog
                            AuditLog.objects.create(
                                user=None,  # Ø³ÙŠØªÙ… ØªØ¹ÙŠÙŠÙ†Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø°ÙŠ Ø£Ù†Ø´Ø£ Ø§Ù„Ù†Ø³Ø®Ø©
                                action='backup_xlsx_sheet_error',
                                details=f'Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ÙˆØ±Ù‚Ø© Ø¹Ù…Ù„ {app_name}_{model_name}: {str(e)}'
                            )
                        except Exception:
                            pass
                        continue
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
        workbook.save(filepath)
        logger.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© XLSX Ø¨Ù†Ø¬Ø§Ø­: {filepath} - ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ {sheet_count} ÙˆØ±Ù‚Ø© Ø¹Ù…Ù„")
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙƒÙ€ XLSX: {str(e)}")
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ ÙÙŠ audit log
        try:
            from core.models import AuditLog
            AuditLog.objects.create(
                user=None,  # Ø³ÙŠØªÙ… ØªØ¹ÙŠÙŠÙ†Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø°ÙŠ Ø£Ù†Ø´Ø£ Ø§Ù„Ù†Ø³Ø®Ø©
                action='backup_xlsx_save_error',
                details=f'Ø®Ø·Ø£ ÙƒØ¨ÙŠØ± ÙÙŠ Ø­ÙØ¸ Ù…Ù„Ù XLSX: {str(e)}'
            )
        except Exception:
            pass
        raise e


def load_backup_from_xlsx(file_obj, user=None):
    """ØªØ­ÙˆÙŠÙ„ Ù…Ù„Ù Excel Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ JSON Ù„Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù…Ø¹ Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ­Ù…Ù‘Ù„"""
    try:
        from openpyxl import load_workbook
        from django.apps import apps as django_apps
        
        logger.info("Ø¨Ø¯Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Excel Ù„Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©")
        workbook = load_workbook(file_obj)
        
        # Ù‚Ø±Ø§Ø¡Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† ÙˆØ±Ù‚Ø© "Backup Info"
        backup_data = {
            'metadata': {},
            'data': {}
        }
        
        info_sheet = None
        if "Backup Info" in workbook.sheetnames:
            info_sheet = workbook["Backup Info"]
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            for row in info_sheet.iter_rows(min_row=1, max_row=5, values_only=True):
                if len(row) >= 2 and row[0] and row[1]:
                    if row[0] == 'Backup Name':
                        backup_data['metadata']['backup_name'] = str(row[1])
                    elif row[0] == 'Created At':
                        backup_data['metadata']['created_at'] = str(row[1])
                    elif row[0] == 'Created By':
                        backup_data['metadata']['created_by'] = str(row[1])
                    elif row[0] == 'Total Tables':
                        backup_data['metadata']['total_tables'] = int(row[1]) if row[1] else 0
                    elif row[0] == 'Total Records':
                        backup_data['metadata']['total_records'] = int(row[1]) if row[1] else 0
        
        # ØªØ¬Ù‡ÙŠØ² Ù‚Ø§Ø¦Ù…Ø© Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø°ÙƒÙŠØ©
        available_apps = {cfg.name for cfg in django_apps.get_app_configs()}
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¨Ø§Ù‚ÙŠ Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ø¹Ù…Ù„
        for sheet_name in workbook.sheetnames:
            if sheet_name == "Backup Info":
                continue
                
            sheet = workbook[sheet_name]
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ø³Ù… ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù…Ù„ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ app_name Ùˆ model_name Ø¨Ø·Ø±ÙŠÙ‚Ø© Ù…ØªØ­Ù…Ù‘Ù„Ø©
            resolved_app = None
            resolved_model = None
            raw = str(sheet_name)
            parts = raw.split('_')
            # Ø¬Ø±Ù‘Ø¨ Ø¬Ù…ÙŠØ¹ Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ø­ØªÙ‰ ØªØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬Ø§Ù‹ Ù…Ø¹Ø±ÙˆÙØ§Ù‹
            for i in range(1, len(parts)):
                cand_app = '_'.join(parts[:i])
                cand_model = '_'.join(parts[i:])
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù„Ø§Ø­Ù‚Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ø§Ù„ØªÙŠ ØªÙ…Øª Ø¥Ø¶Ø§ÙØªÙ‡Ø§ Ù„ØªÙØ§Ø¯ÙŠ Ø§Ù„ØªÙƒØ±Ø§Ø±
                cand_model = cand_model.rstrip('_0123456789')
                # ØªØ­Ù‚Ù‘Ù‚ Ù…Ù† ØªÙˆØ§ÙÙ‚ Ø§Ø³Ù… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
                if cand_app in available_apps:
                    try:
                        # apps.get_model ÙŠØªÙˆÙ‚Ø¹ app_label.model_name (model_name ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† lower)
                        mdl = django_apps.get_model(f"{cand_app}.{cand_model.lower()}")
                        if mdl is not None:
                            resolved_app = cand_app
                            resolved_model = cand_model
                            break
                    except Exception:
                        continue
            if not resolved_app or not resolved_model:
                # fallback: Ø§Ø³ØªØ®Ø¯Ù… Ø£ÙˆÙ„ Ø¬Ø²Ø¡ ÙƒØªØ·Ø¨ÙŠÙ‚ ÙˆØ§Ù„Ø¨Ø§Ù‚ÙŠ ÙƒÙ†Ù…ÙˆØ°Ø¬ Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù„Ø§Ø­Ù‚Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
                resolved_app = parts[0]
                resolved_model = '_'.join(parts[1:]).rstrip('_0123456789') or 'default'
            app_name = resolved_app
            model_name = resolved_model
            
            # Ø³Ø¬Ù‘Ù„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØµØ­ÙŠØ­ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© ØºØ§Ù…Ø¶Ø§Ù‹
            if AUDIT_AVAILABLE and user and raw != f"{app_name}_{model_name}":
                try:
                    AuditLog.objects.create(
                        user=user,
                        action='backup_restore_xlsx_sheet_resolved',
                        details=f'ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© "{raw}" Ø¥Ù„Ù‰ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ "{app_name}" ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬ "{model_name}"'
                    )
                except Exception:
                    pass
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if app_name not in backup_data['data']:
                backup_data['data'][app_name] = {}
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„ÙˆØ±Ù‚Ø©
            rows = list(sheet.iter_rows(values_only=True))
            if len(rows) < 1:
                backup_data['data'][app_name][model_name] = []
                continue
            
            # Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            headers = [str(h) if h else f'col_{i}' for i, h in enumerate(rows[0])]
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Django
            model_data = []
            for row_data in rows[1:]:  # ØªØ¬Ø§Ù‡Ù„ ØµÙ Ø§Ù„Ø±Ø¤ÙˆØ³
                if not any(cell for cell in row_data):  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ©
                    continue
                
                try:
                    # Ø£ÙˆÙ„ Ø¹Ù…ÙˆØ¯ Ù‡Ùˆ ID
                    record_id = row_data[0] if len(row_data) > 0 and row_data[0] is not None else None
                    # Excel Ù‚Ø¯ ÙŠØ­ÙˆÙ‘Ù„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¥Ù„Ù‰ float
                    if isinstance(record_id, float):
                        record_id = int(record_id) if float(record_id).is_integer() else record_id
                    
                    # Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù‡ÙŠ Ø§Ù„Ø­Ù‚ÙˆÙ„
                    fields = {}
                    for i, (header, value) in enumerate(zip(headers[1:], row_data[1:]), 1):
                        if value is not None:
                            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
                            if isinstance(value, (int, float, bool)):
                                fields[header] = value
                            elif isinstance(value, str):
                                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø±Ù‚Ù… Ø£Ùˆ boolean Ø¥Ø°Ø§ Ø£Ù…ÙƒÙ†
                                try:
                                    v = value.strip()
                                    # Ø­Ø§ÙˆÙ„ Ù‚Ø±Ø§Ø¡Ø© JSON Ù„Ù„Ù‚ÙˆØ§Ø¦Ù…/Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ (Ù…Ø«Ù„ Ù‚ÙŠÙ… ManyToMany Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© ÙƒØ³Ù„Ø³Ù„Ø©)
                                    if (v.startswith('[') and v.endswith(']')) or (v.startswith('{') and v.endswith('}')):
                                        try:
                                            parsed = json.loads(v)
                                            fields[header] = parsed
                                            continue
                                        except Exception:
                                            pass
                                    # Ù‚Ø§Ø¦Ù…Ø© Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„ Ù„Ù„Ø£Ø±Ù‚Ø§Ù…: 1,2,3
                                    if ',' in v:
                                        parts_vals = [p.strip() for p in v.split(',') if p.strip()]
                                        if parts_vals and all(p.replace('.', '', 1).isdigit() for p in parts_vals):
                                            # Ø­ÙˆÙ‘Ù„ Ø¥Ù„Ù‰ Ø£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø© Ø¹Ù†Ø¯Ù…Ø§ Ù…Ù…ÙƒÙ†
                                            as_numbers = [int(p) if p.isdigit() else float(p) for p in parts_vals]
                                            fields[header] = as_numbers
                                            continue
                                    if v.lower() in ['true', 'false']:
                                        fields[header] = v.lower() == 'true'
                                    elif v.isdigit():
                                        fields[header] = int(v)
                                    elif v.replace('.', '', 1).isdigit():
                                        fields[header] = float(v)
                                    else:
                                        fields[header] = value
                                except:
                                    fields[header] = value
                            else:
                                fields[header] = str(value) if value is not None else None
                        else:
                            fields[header] = None
                    
                    # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„ Ø¨ØªÙ†Ø³ÙŠÙ‚ Django
                    record = {
                        'pk': record_id,
                        'model': f"{app_name}.{model_name.lower()}",
                        'fields': fields
                    }
                    model_data.append(record)
                    
                except Exception as row_error:
                    logger.warning(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© ØµÙ ÙÙŠ ÙˆØ±Ù‚Ø© {sheet_name}: {str(row_error)}")
                    continue
            
            backup_data['data'][app_name][model_name] = model_data
            logger.debug(f"ØªÙ… Ù‚Ø±Ø§Ø¡Ø© {len(model_data)} Ø³Ø¬Ù„ Ù…Ù† ÙˆØ±Ù‚Ø© {sheet_name}")
        
        logger.info(f"ØªÙ… ØªØ­ÙˆÙŠÙ„ Ù…Ù„Ù Excel Ø¨Ù†Ø¬Ø§Ø­ - {len(backup_data['data'])} ØªØ·Ø¨ÙŠÙ‚")
        return backup_data
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Excel: {str(e)}")
        raise Exception(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Excel: {str(e)}")


def convert_field_value(field, value):
    """ØªØ­ÙˆÙŠÙ„ Ù‚ÙŠÙ…Ø© Ø§Ù„Ø­Ù‚Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„ØµØ­ÙŠØ­"""
    if value is None or value == '':
        return value
    
    try:
        field_type = field.get_internal_type()
        
        if field_type in ['DecimalField']:
            if isinstance(value, str):
                return Decimal(value)
            return Decimal(str(value))
        elif field_type in ['IntegerField', 'BigIntegerField', 'SmallIntegerField', 'PositiveIntegerField']:
            if isinstance(value, str):
                return int(float(value)) if '.' in value else int(value)
            return int(value)
        elif field_type in ['FloatField']:
            if isinstance(value, str):
                return float(value)
            return float(value)
        elif field_type in ['BooleanField']:
            if isinstance(value, str):
                return value.lower() in ('true', '1', 'yes', 'on')
            return bool(value)
        elif field_type in ['DateTimeField']:
            if isinstance(value, str):
                from django.utils.dateparse import parse_datetime
                return parse_datetime(value)
            return value
        elif field_type in ['DateField']:
            if isinstance(value, str):
                from django.utils.dateparse import parse_date
                return parse_date(value)
            return value
        elif field_type in ['TimeField']:
            if isinstance(value, str):
                from django.utils.dateparse import parse_time
                return parse_time(value)
            return value
        else:
            return value
    except Exception:
        # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ØŒ Ø£Ø¹Ø¯ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        return value


def perform_backup_restore(backup_data, clear_data=False, user=None):
    """ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©"""
    try:
        logger.info("Ø¨Ø¯Ø¡ ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©")
        
        # ØªØ³Ø¬ÙŠÙ„ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ø£Ù†Ø´Ø·Ø©
        log_audit(user, 'create', _('Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©'))

        # ØªÙ‡ÙŠØ¦Ø© ØªØªØ¨Ø¹ Ø§Ù„ØªÙ‚Ø¯Ù…
        flat_tables = []
        total_records_expected = 0
        if isinstance(backup_data, dict) and 'data' in backup_data:
            for app_name, app_data in backup_data['data'].items():
                for model_name, model_records in app_data.items():
                    if isinstance(model_records, list):
                        rec_count = len(model_records)
                        total_records_expected += rec_count
                        flat_tables.append({
                            'app_name': app_name,
                            'model_name': model_name,
                            'display_name': f"{app_name}.{model_name}",
                            'record_count': rec_count,
                            'status': 'pending',
                            'progress': 0,
                            'actual_records': 0,
                            'error': None
                        })

        # ØªØ³Ø¬ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
        log_audit(user, 'view', _('ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© - {} Ø¬Ø¯ÙˆÙ„ Ø¨Ø¥Ø¬Ù…Ø§Ù„ÙŠ {} Ø³Ø¬Ù„').format(len(flat_tables), total_records_expected))

        progress_data = get_restore_progress_data()
        progress_data.update({
            'is_running': True,
            'status': 'starting',
            'error': None,
            'percentage': 0,
            'current_table': 'Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©...',
            'processed_tables': 0,
            'total_tables': len(flat_tables),
            'processed_records': 0,
            'total_records': total_records_expected,
            'estimated_time': 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨...',
            'tables_status': flat_tables
        })
        set_restore_progress_data(progress_data)
        
        # Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨ Ø°Ù„Ùƒ
        if clear_data:
            logger.info("Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©...")
            
            # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ù†Ø¸Ø§Ù… (contenttypes, auth, admin, sessions)
            skip_apps = {'contenttypes', 'auth', 'admin', 'sessions'}
            
            # Ø¨Ù†Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ¨Ø¹ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
            dep_map = {}
            model_map = {}
            for app_config in apps.get_app_configs():
                if app_config.name in skip_apps:
                    continue
                    
                for model in app_config.get_models():
                    # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ Ù„Ø§ ØªÙ†Ø´Ø¦ Ø¬Ø¯Ø§ÙˆÙ„
                    if not model._meta.managed:
                        continue
                        
                    label = f"{app_config.name}.{model._meta.model_name}"
                    dep_map[label] = set()
                    model_map[label] = model

            logger.info(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(model_map)} Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù…Ø³Ø­")
            
            # Ù…Ù„Ø¡ Ø®Ø±ÙŠØ·Ø© Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª
            for label, model in list(model_map.items()):
                for field in model._meta.get_fields():
                    try:
                        if field.is_relation and (field.many_to_one or field.one_to_one) and field.related_model is not None:
                            rel = field.related_model
                            rel_label = f"{rel._meta.app_label}.{rel._meta.model_name}"
                            if rel_label in dep_map:
                                dep_map[rel_label].add(label)
                    except Exception:
                        continue

            # Ø­Ø³Ø§Ø¨ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø­Ø°Ù Ø¨Ø­ÙŠØ« ØªÙØ­Ø°Ù Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø£ÙˆÙ„Ø§Ù‹ (post-order traversal)
            visited = set()
            delete_order = []
            def dfs(label):
                if label in visited:
                    return
                visited.add(label)
                for dep in dep_map.get(label, set()):
                    dfs(dep)
                delete_order.append(label)

            for label in list(model_map.keys()):
                dfs(label)
            
            logger.info(f"ØªÙ… Ø­Ø³Ø§Ø¨ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø­Ø°Ù: {len(delete_order)} Ù†Ù…ÙˆØ°Ø¬")
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ø­Ø°Ù Ø¯Ø§Ø®Ù„ Ù…Ø¹Ø§Ù…Ù„Ø© ÙˆØ¨ØªØ±ØªÙŠØ¨ Ø¢Ù…Ù†
            deleted_stats = []
            failed_deletions = []
            total_deleted_records = 0
            
            try:
                with transaction.atomic():
                    for i, label in enumerate(delete_order):
                        model = model_map.get(label)
                        if model is None:
                            continue
                            
                        try:
                            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù†Ù…ÙˆØ°Ø¬ User
                            UserModel = None
                            try:
                                from django.contrib.auth import get_user_model
                                UserModel = get_user_model()
                            except Exception:
                                UserModel = None

                            if UserModel is not None and getattr(model, '__name__', '').lower() == getattr(UserModel, '__name__', '').lower():
                                # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù… Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
                                fallback_username = '__deleted_user__'
                                fallback = UserModel.objects.filter(username=fallback_username).first()
                                if not fallback:
                                    fallback = UserModel.objects.create(username=fallback_username, is_active=False)

                                # Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆØ¬ÙŠÙ‡ Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ù…Ø±Ø§Ø¯ Ø­Ø°ÙÙ‡Ø§
                                try:
                                    user_ids = list(model.objects.exclude(pk=fallback.pk).values_list('pk', flat=True))
                                    from core.models import AuditLog as _AuditLog
                                    if user_ids:
                                        _AuditLog.objects.filter(user_id__in=user_ids).update(user_id=fallback.pk)
                                except Exception as reassign_err:
                                    logger.warning(f"ÙØ´Ù„ ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆØ¬ÙŠÙ‡ Ù…Ø±Ø§Ø¬Ø¹Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†: {reassign_err}")

                                # Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø¹Ø¯Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
                                qs = model.objects.exclude(pk=fallback.pk)
                                count = qs.count()
                                qs.delete()
                                deleted_stats.append({'table': label, 'deleted': count})
                                total_deleted_records += count
                                logger.debug(f"ØªÙ… Ù…Ø³Ø­ {count} Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† {label} ({i+1}/{len(delete_order)})")
                                continue

                            # Ø§Ù„Ø­Ø°Ù Ø§Ù„Ø¹Ø§Ø¯ÙŠ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø£Ø®Ø±Ù‰
                            count = model.objects.all().count()
                            if count > 0:  # ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¨ÙŠØ§Ù†Ø§Øª
                                model.objects.all().delete()
                                deleted_stats.append({'table': label, 'deleted': count})
                                total_deleted_records += count
                                logger.debug(f"ØªÙ… Ù…Ø³Ø­ {count} Ø³Ø¬Ù„ Ù…Ù† {label} ({i+1}/{len(delete_order)})")
                            
                        except ProtectedError as p_err:
                            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ÙØ´Ù„ Ø­Ø°ÙÙ‡Ø§ Ø¨Ø³Ø¨Ø¨ Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ø­Ù…ÙŠØ©
                            failed_deletions.append({
                                'table': label,
                                'error': 'ProtectedError',
                                'details': str(p_err)
                            })
                            logger.warning(f"ØªØ¹Ø°Ø± Ù…Ø³Ø­ {label} Ø¨Ø³Ø¨Ø¨ Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ø­Ù…ÙŠØ©: {str(p_err)}")
                            continue
                            
                        except Exception as del_exc:
                            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙŠ ÙØ´Ù„ Ø­Ø°ÙÙ‡Ø§ Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø£Ø®Ø±Ù‰
                            failed_deletions.append({
                                'table': label,
                                'error': str(type(del_exc).__name__),
                                'details': str(del_exc)
                            })
                            logger.warning(f"ØªØ¹Ø°Ø± Ù…Ø³Ø­ {label}: {str(del_exc)}")
                            continue
                    
                # ØªØ³Ø¬ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                logger.info(f"ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ù…Ø³ÙˆØ­Ø©: {total_deleted_records}")
                log_audit(user, 'delete', f'ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© - ØªÙ… Ù…Ø³Ø­ {total_deleted_records} Ø³Ø¬Ù„ Ù…Ù† {len(deleted_stats)} Ø¬Ø¯ÙˆÙ„')
                
                if failed_deletions:
                    failed_count = len(failed_deletions)
                    log_audit(user, 'warning', f'ÙØ´Ù„ Ù…Ø³Ø­ {failed_count} Ø¬Ø¯ÙˆÙ„ Ø¨Ø³Ø¨Ø¨ Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ø­Ù…ÙŠØ© Ø£Ùˆ Ø£Ø®Ø·Ø§Ø¡ Ø£Ø®Ø±Ù‰')
                    logger.warning(f"ÙØ´Ù„ Ù…Ø³Ø­ {failed_count} Ø¬Ø¯ÙˆÙ„: {[f['table'] for f in failed_deletions]}")
                    
            except Exception as tx_error:
                logger.error(f"ÙØ´Ù„ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø©: {str(tx_error)}")
                log_audit(user, 'error', f'ÙØ´Ù„ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©: {str(tx_error)}')
                # Ù„Ø§ Ù†Ø±Ù…ÙŠ Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù‡Ù†Ø§ Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©
        # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if 'data' in backup_data:
            total_records = 0
            restored_count = 0
            processed_tables = 0
            processed_records = 0
            table_index = -1
            start_time = time.time()
            errors = []
            for app_name, app_data in backup_data['data'].items():
                for model_name, model_records in app_data.items():
                    if isinstance(model_records, list):
                        table_index += 1
                        expected_in_table = len(model_records)
                        # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¬Ø§Ø±ÙŠ
                        pd = get_restore_progress_data()
                        ts = pd.get('tables_status', [])
                        if table_index < len(ts):
                            ts[table_index]['status'] = 'processing'
                            ts[table_index]['progress'] = 0
                        pd.update({
                            'status': 'processing',
                            'current_table': f'Ø§Ø³ØªØ¹Ø§Ø¯Ø© {app_name}.{model_name}...',
                            'tables_status': ts
                        })
                        set_restore_progress_data(pd)

                        processed_in_table = 0
                        for record in model_records:
                            try:
                                # ØªØµØ­ÙŠØ­ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
                                original_app_name = app_name
                                original_model_name = model_name
                                
                                if app_name == 'revenues':
                                    app_name = 'revenues_expenses'
                                elif app_name == 'assets':
                                    app_name = 'assets_liabilities'
                                elif app_name == 'expenses':
                                    app_name = 'revenues_expenses'
                                elif app_name == 'liabilities':
                                    app_name = 'assets_liabilities'
                                
                                model_label = f"{app_name}.{model_name.lower()}"
                                
                                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ù„Ù€ AuditLog - ØªØµØ­ÙŠØ­ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
                                if model_label == 'core.auditlog':
                                    fields = record.get('fields', {})
                                    if 'action' in fields and 'action_type' not in fields:
                                        fields['action_type'] = fields.pop('action')
                                    if 'details' in fields and 'description' not in fields:
                                        fields['description'] = fields.pop('details')
                                
                                model = apps.get_model(model_label)
                                fields = record.get('fields', {})
                                # ØªØ­ÙˆÙŠÙ„Ø§Øª ØªÙˆØ§ÙÙ‚ÙŠØ© Ù„Ø­Ù‚ÙˆÙ„ Ù‚Ø¯ÙŠÙ…Ø© Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒØ§Ø¦Ù†
                                try:
                                    # Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª: ØªØ­ÙˆÙŠÙ„ is_service Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø¥Ù„Ù‰ product_type Ø§Ù„Ø¬Ø¯ÙŠØ¯
                                    if model_label == 'products.product' and 'is_service' in fields and 'product_type' not in fields:
                                        is_service_val = fields.get('is_service')
                                        fields['product_type'] = 'service' if bool(is_service_val) else 'physical'
                                        if AUDIT_AVAILABLE and user:
                                            try:
                                                log_audit(user, 'import', 'ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ… "is_service" Ø¥Ù„Ù‰ "product_type" Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©')
                                            except Exception:
                                                pass
                                    # Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…Ø®Ø²ÙˆÙ†: ØªØ­ÙˆÙŠÙ„ total_amount Ø§Ù„Ù‚Ø¯ÙŠÙ… Ø¥Ù„Ù‰ total_cost
                                    if model_label == 'inventory.inventorymovement' and 'total_amount' in fields and 'total_cost' not in fields:
                                        fields['total_cost'] = fields.get('total_amount')
                                        if AUDIT_AVAILABLE and user:
                                            try:
                                                log_audit(user, 'import', 'ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ… "total_amount" Ø¥Ù„Ù‰ "total_cost" ÙÙŠ Ø­Ø±ÙƒØ© Ø§Ù„Ù…Ø®Ø²ÙˆÙ† Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©')
                                            except Exception:
                                                pass
                                except Exception:
                                    # ØªØ¬Ø§Ù‡Ù„ Ø£ÙŠ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„ØªÙˆØ§ÙÙ‚ÙŠØ©
                                    pass
                                pk = record.get('pk', None)
                                obj = model()
                                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ø§Ù„ÙØ§Ø±ØºØ© ÙˆØ­Ù‚ÙˆÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª
                                m2m_fields = {}
                                model_field_names = [f.name for f in model._meta.get_fields()]
                                for field in model._meta.get_fields():
                                    fname = field.name
                                    # Ø§Ø¹ØªØ¨Ø± Ø§Ù„Ø­Ù‚Ù„ Ø¥Ù„Ø²Ø§Ù…ÙŠØ§Ù‹ Ø¥Ø°Ø§ ÙƒØ§Ù† null=False ÙÙ‚Ø· (blank Ø®Ø§Øµ Ø¨Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆÙ„ÙŠØ³ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)
                                    is_required = (getattr(field, 'null', True) is False) and not getattr(field, 'auto_created', False) and fname != 'id'
                                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© ForeignKey Ùˆ OneToOne
                                    if field.is_relation and (field.many_to_one or field.one_to_one):
                                        rel_model = field.related_model
                                        rel_value = fields.get(fname)
                                        if rel_value not in [None, '']:
                                            try:
                                                rel_obj = rel_model.objects.filter(pk=rel_value).first()
                                                setattr(obj, fname, rel_obj)
                                                if rel_obj is None:
                                                    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø­Ù‚Ù„ FK Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ…Ø·Ù„ÙˆØ¨ ÙˆÙ‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¹Ø±Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©ØŒ Ø¹ÙŠÙ‘Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ
                                                    try:
                                                        from django.contrib.auth import get_user_model
                                                        UserModel = get_user_model()
                                                    except Exception:
                                                        UserModel = None
                                                    if is_required and UserModel and user and isinstance(user, UserModel) and (rel_model == UserModel or issubclass(rel_model, UserModel)):
                                                        setattr(obj, fname, user)
                                                        if AUDIT_AVAILABLE and user:
                                                            log_audit(user, 'import', f'ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ ÙƒÙ‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø­Ù‚Ù„ "{fname}" (Ù…Ø±Ø¬Ø¹ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯) ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_label}')
                                                    elif AUDIT_AVAILABLE and user:
                                                        AuditLog.objects.create(
                                                            user=user,
                                                            action='backup_restore_fk_missing',
                                                            details=f'Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø±ØªØ¨Ø· Ù„Ù„Ø­Ù‚Ù„ "{fname}" ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_label} Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©. ØªÙ… ØªØ¹ÙŠÙŠÙ† None.'
                                                        )
                                            except Exception as fk_error:
                                                setattr(obj, fname, None)
                                                if AUDIT_AVAILABLE and user:
                                                    AuditLog.objects.create(
                                                        user=user,
                                                        action='backup_restore_fk_error',
                                                        details=f'Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø±ØªØ¨Ø· Ù„Ù„Ø­Ù‚Ù„ "{fname}" ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_label}: {str(fk_error)}'
                                                    )
                                        else:
                                            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø­Ù‚Ù„ FK Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆÙ…Ø·Ù„ÙˆØ¨ ÙˆÙ‚ÙŠÙ…ØªÙ‡ Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ Ø¹ÙŠÙ‘Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ ÙƒÙ…Ù‚Ø¯Ø§Ø± Ø§ÙØªØ±Ø§Ø¶ÙŠ
                                            try:
                                                from django.contrib.auth import get_user_model
                                                UserModel = get_user_model()
                                            except Exception:
                                                UserModel = None
                                            if is_required and UserModel and user and isinstance(user, UserModel) and (rel_model == UserModel or issubclass(rel_model, UserModel)):
                                                try:
                                                    setattr(obj, fname, user)
                                                    if AUDIT_AVAILABLE and user:
                                                        log_audit(user, 'import', f'ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ ÙƒÙ‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø­Ù‚Ù„ "{fname}" Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_label}')
                                                except Exception:
                                                    setattr(obj, fname, None)
                                            else:
                                                setattr(obj, fname, None)
                                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­Ù‚ÙˆÙ„ ManyToMany
                                    elif field.many_to_many:
                                        rel_model = field.related_model
                                        rel_values = fields.get(fname)
                                        if rel_values:
                                            m2m_fields[fname] = rel_values
                                    # Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ø§Ù„ÙØ§Ø±ØºØ©
                                    elif is_required and (fname not in fields or fields[fname] in [None, '']):
                                        if getattr(field, 'default', models.NOT_PROVIDED) is not models.NOT_PROVIDED:
                                            try:
                                                setattr(obj, fname, field.get_default())
                                            except Exception:
                                                setattr(obj, fname, getattr(field, 'default', None))
                                        elif getattr(field, 'get_internal_type', lambda: None)() in ['CharField', 'TextField']:
                                            setattr(obj, fname, '')
                                        elif getattr(field, 'get_internal_type', lambda: None)() == 'BooleanField':
                                            setattr(obj, fname, False)
                                        elif getattr(field, 'get_internal_type', lambda: None)() in ['IntegerField', 'BigIntegerField', 'SmallIntegerField', 'PositiveIntegerField']:
                                            setattr(obj, fname, 0)
                                        elif getattr(field, 'get_internal_type', lambda: None)() in ['FloatField']:
                                            setattr(obj, fname, 0.0)
                                        elif getattr(field, 'get_internal_type', lambda: None)() in ['DecimalField']:
                                            setattr(obj, fname, Decimal('0'))
                                        elif getattr(field, 'get_internal_type', lambda: None)() == 'DateTimeField':
                                            from django.utils import timezone
                                            setattr(obj, fname, timezone.now())
                                        elif getattr(field, 'get_internal_type', lambda: None)() == 'DateField':
                                            from django.utils import timezone
                                            setattr(obj, fname, timezone.now().date())
                                        else:
                                            setattr(obj, fname, None)
                                        if AUDIT_AVAILABLE and user:
                                            try:
                                                AuditLog.objects.create(
                                                    user=user,
                                                    action='backup_restore_field_fix',
                                                    details=f'ØªÙ… ØªØ¹ÙŠÙŠÙ† Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø­Ù‚Ù„ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠ "{fname}" ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_label} Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©.'
                                                )
                                            except Exception:
                                                pass
                                    # Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
                                    elif fname in fields:
                                        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ…Ø© None ÙˆØ­Ù‚Ù„ ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù€ null ÙÙ‚Ù… Ø¨Ø¶Ø¨Ø· Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¢Ù…Ù†Ø©
                                        val = fields[fname]
                                        if (val is None) and (getattr(field, 'null', True) is False) and not field.is_relation and not field.many_to_many:
                                            internal = getattr(field, 'get_internal_type', lambda: None)()
                                            if getattr(field, 'default', models.NOT_PROVIDED) is not models.NOT_PROVIDED:
                                                try:
                                                    safe_val = field.get_default()
                                                except Exception:
                                                    safe_val = getattr(field, 'default', None)
                                            elif internal in ['CharField', 'TextField']:
                                                safe_val = ''
                                            elif internal == 'BooleanField':
                                                safe_val = False
                                            elif internal in ['IntegerField', 'BigIntegerField', 'SmallIntegerField', 'PositiveIntegerField']:
                                                safe_val = 0
                                            elif internal == 'FloatField':
                                                safe_val = 0.0
                                            elif internal == 'DecimalField':
                                                safe_val = Decimal('0')
                                            elif internal == 'DateTimeField':
                                                from django.utils import timezone
                                                safe_val = timezone.now()
                                            elif internal == 'DateField':
                                                from django.utils import timezone
                                                safe_val = timezone.now().date()
                                            else:
                                                safe_val = ''
                                            setattr(obj, fname, safe_val)
                                            if AUDIT_AVAILABLE and user:
                                                try:
                                                    log_audit(user, 'update', f'ØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ù‚ÙŠÙ…Ø© None Ø¨Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø­Ù‚Ù„ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠ "{fname}" ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_label}.')
                                                except Exception:
                                                    pass
                                        else:
                                            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„ØµØ­ÙŠØ­ Ù‚Ø¨Ù„ Ø§Ù„ØªØ¹ÙŠÙŠÙ†
                                            converted_val = convert_field_value(field, val)
                                            setattr(obj, fname, converted_val)
                                # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø­Ù‚ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                                for field_name in fields.keys():
                                    if field_name not in model_field_names:
                                        if AUDIT_AVAILABLE and user:
                                            try:
                                                log_audit(user, 'view', f'ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø­Ù‚Ù„ ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ "{field_name}" ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_label} Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©.')
                                            except Exception:
                                                pass
                                if pk:
                                    obj.pk = pk
                                try:
                                    obj.save()
                                except Exception as save_error:
                                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆØ§Ù„Ù‚ÙŠÙˆØ¯
                                    error_msg = str(save_error).lower()
                                    if 'duplicate key' in error_msg or 'unique constraint' in error_msg:
                                        # ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±ØŒ Ø­Ø§ÙˆÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¥Ø¯Ø±Ø§Ø¬
                                        try:
                                            if pk:
                                                existing_obj = model.objects.filter(pk=pk).first()
                                                if existing_obj:
                                                    # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
                                                    for fname, val in fields.items():
                                                        if hasattr(existing_obj, fname) and fname != 'id':
                                                            setattr(existing_obj, fname, val)
                                                    existing_obj.save()
                                                    if AUDIT_AVAILABLE and user:
                                                        log_audit(user, 'update', f'ØªÙ… ØªØ­Ø¯ÙŠØ« Ø³Ø¬Ù„ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ {model_label} Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙƒØ±Ø±')
                                                else:
                                                    # Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø¨Ø§Ù„Ù€ PKØŒ Ø¬Ø±Ø¨ Ø¨Ø¯ÙˆÙ† PK
                                                    obj.pk = None
                                                    obj.save()
                                            else:
                                                # Ø¬Ø±Ø¨ Ø­ÙØ¸ Ø¨Ø¯ÙˆÙ† PK
                                                obj.pk = None
                                                obj.save()
                                        except Exception as retry_error:
                                            # Ø¥Ø°Ø§ ÙØ´Ù„ ÙƒÙ„ Ø´ÙŠØ¡ØŒ ØªØ¬Ø§Ù‡Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¬Ù„
                                            logger.warning(f"ØªØ¹Ø°Ø± Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø³Ø¬Ù„ {model_label} Ø¨Ø³Ø¨Ø¨ ØªÙƒØ±Ø§Ø±: {str(retry_error)}")
                                            if AUDIT_AVAILABLE and user:
                                                log_audit(user, 'error', f'ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø³Ø¬Ù„ Ù…ÙƒØ±Ø± ÙÙŠ {model_label}: {str(retry_error)}')
                                            total_records += 1
                                            continue
                                    else:
                                        # Ø®Ø·Ø£ Ø¢Ø®Ø± ØºÙŠØ± Ø§Ù„ØªÙƒØ±Ø§Ø±
                                        raise save_error
                                # ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø­Ù‚ÙˆÙ„ ManyToMany Ø¨Ø¹Ø¯ Ø§Ù„Ø­ÙØ¸
                                for m2m_name, m2m_values in m2m_fields.items():
                                    try:
                                        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù‚ÙŠÙ…Ø© Ù†ØµÙŠØ©ØŒ Ø­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø±Ù‚Ø§Ù…
                                        if isinstance(m2m_values, str):
                                            v = m2m_values.strip()
                                            try:
                                                if (v.startswith('[') and v.endswith(']')):
                                                    m2m_values = json.loads(v)
                                                else:
                                                    tokens = [p.strip() for p in v.split(',') if p.strip()]
                                                    if tokens and all(t.replace('.', '', 1).isdigit() for t in tokens):
                                                        m2m_values = [int(t) if t.isdigit() else float(t) for t in tokens]
                                            except Exception:
                                                pass
                                        # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø£Ø¹Ø¯Ø§Ø¯ ØµØ­ÙŠØ­Ø© Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù†
                                        if isinstance(m2m_values, list):
                                            norm_values = []
                                            for vv in m2m_values:
                                                if isinstance(vv, float) and float(vv).is_integer():
                                                    norm_values.append(int(vv))
                                                elif isinstance(vv, (int,)):
                                                    norm_values.append(vv)
                                                elif isinstance(vv, str) and vv.isdigit():
                                                    norm_values.append(int(vv))
                                                else:
                                                    # Ø§ØªØ±Ùƒ Ø§Ù„Ù‚ÙŠÙ…Ø© ÙƒÙ…Ø§ Ù‡ÙŠ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙ…ÙƒÙ† ØªØ­ÙˆÙŠÙ„Ù‡Ø§
                                                    norm_values.append(vv)
                                            m2m_values = norm_values
                                        m2m_manager = getattr(obj, m2m_name)
                                        m2m_manager.set(m2m_values)
                                    except Exception as m2m_error:
                                        if AUDIT_AVAILABLE and user:
                                            log_audit(user, 'error', f'Ø®Ø·Ø£ ÙÙŠ ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø­Ù‚Ù„ ManyToMany "{m2m_name}" ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ {model_label}: {str(m2m_error)}')
                                restored_count += 1
                                processed_in_table += 1
                                processed_records += 1
                                # ØªØ­Ø¯ÙŠØ« ØªÙ‚Ø¯Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙˆØ§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ø¹Ø§Ù…
                                pd = get_restore_progress_data()
                                ts = pd.get('tables_status', [])
                                if table_index < len(ts) and expected_in_table > 0:
                                    table_progress = int((processed_in_table / expected_in_table) * 100)
                                    ts[table_index]['progress'] = table_progress
                                    ts[table_index]['actual_records'] = processed_in_table
                                # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ÙˆÙ‚Øª ÙˆØ§Ù„ÙƒÙ†ØªØ±ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù…
                                elapsed = time.time() - start_time
                                overall_percentage = 0
                                # Ø§Ø³ØªØ®Ø¯Ù… total_records_expected Ø§Ù„Ù…Ø­Ø³ÙˆØ¨ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† total_records Ø§Ù„Ù…ØªØºÙŠØ±
                                if total_records_expected > 0:
                                    overall_percentage = int((processed_records / total_records_expected) * 100)
                                
                                pd.update({
                                    'processed_tables': processed_tables,
                                    'processed_records': processed_records,
                                    'percentage': overall_percentage,
                                    'tables_status': ts
                                })
                                set_restore_progress_data(pd)
                            except Exception as record_error:
                                logger.warning(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø³Ø¬Ù„ ÙÙŠ {app_name}.{model_name}: {str(record_error)}")
                                errors.append(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø³Ø¬Ù„ ÙÙŠ {app_name}.{model_name}: {str(record_error)}")
                                continue
            logger.info(f"ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© {restored_count} Ù…Ù† {total_records} Ø³Ø¬Ù„")
            if AUDIT_AVAILABLE and user:
                try:
                    log_audit(user, 'create', f'ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© {restored_count} Ø³Ø¬Ù„ Ù…Ù† Ø£ØµÙ„ {total_records}. Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡: {len(errors)}')
                    if errors:
                        log_audit(user, 'error', '\n'.join(errors))
                except Exception:
                    pass
            # Ù„Ø§ Ù†ÙØ´Ù„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¹Ù†Ø¯ ÙˆØ¬ÙˆØ¯ Ø£Ø®Ø·Ø§Ø¡ Ø¬Ø²Ø¦ÙŠØ©Ø› ØªÙ… ØªØ³Ø¬ÙŠÙ„Ù‡Ø§ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ø£Ù†Ø´Ø·Ø© Ø¨Ø§Ù„ÙØ¹Ù„
            # ÙŠÙ…ÙƒÙ† Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¹Ø±Ø¶ ØªØ­Ø°ÙŠØ± ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø¥Ø°Ø§ Ù„Ø²Ù…ØŒ Ø¯ÙˆÙ† Ø±Ù…ÙŠ Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ù‡Ù†Ø§
            logger.info("ØªÙ… Ø¥ØªÙ…Ø§Ù… Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨Ù†Ø¬Ø§Ø­")
            
            # ØªØ³Ø¬ÙŠÙ„ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ø£Ù†Ø´Ø·Ø©
            log_audit(user, 'create', _('ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨Ù†Ø¬Ø§Ø­ - {} Ø¬Ø¯ÙˆÙ„ØŒ {} Ø³Ø¬Ù„ Ù…Ø³ØªØ¹Ø§Ø¯').format(processed_tables, restored_count))
            
            # Ø¥Ù†Ù‡Ø§Ø¡ Ø­Ø§Ù„Ø© Ø§Ù„ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø¶Ù…Ø§Ù† 100%
            pd = get_restore_progress_data()
            # ØªØ£ÙƒØ¯ Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ù…ÙƒØªÙ…Ù„Ø©
            ts = pd.get('tables_status', [])
            for table_status in ts:
                table_status['status'] = 'completed'
                table_status['progress'] = 100
            pd.update({
                'status': 'completed',
                'is_running': False,
                'percentage': 100,
                'processed_records': total_records_expected,  # ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
                'current_table': 'ØªÙ… Ø¥ØªÙ…Ø§Ù… Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨Ù†Ø¬Ø§Ø­! âœ…',
                'estimated_time': 'Ø§ÙƒØªÙ…Ù„',
                'tables_status': ts
            })
            set_restore_progress_data(pd)
            # ØªÙ†Ø¸ÙŠÙ ÙƒØ§Ø´ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨Ø¹Ø¯ 10 Ø«ÙˆØ§Ù†ÙŠ
            def cleanup_restore_cache():
                time.sleep(10)
                cache.delete('restore_progress')
                cache.delete('restore_last_update')
                cache.delete('restore_last_percentage')
            threading.Thread(target=cleanup_restore_cache, daemon=True).start()
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†Ø³Ø®Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª ÙˆØ³Ø§Ø¦Ø·ØŒ Ø³Ø¬Ù‘Ù„ Ø°Ù„Ùƒ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ù„ØªÙˆØ¹ÙŠØ© Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„
        try:
            if isinstance(backup_data, dict) and 'media_files' in backup_data and backup_data['media_files']:
                if AUDIT_AVAILABLE and user:
                    try:
                        log_audit(user, 'view', f'ØªØ­ØªÙˆÙŠ Ø§Ù„Ù†Ø³Ø®Ø© Ø¹Ù„Ù‰ {len(backup_data["media_files"]) } Ù…Ù„Ù ÙˆØ³Ø§Ø¦Ø· (system/*). ÙŠØªØ·Ù„Ø¨ Ù†Ù‚Ù„Ù‡Ø§ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø¥Ù„Ù‰ MEDIA_ROOT.')
                    except Exception:
                        pass
        except Exception:
            pass
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†Ø³Ø®Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª ØªØ±Ø¬Ù…Ø©ØŒ Ø³Ø¬Ù‘Ù„ Ø°Ù„Ùƒ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ù„ØªÙˆØ¹ÙŠØ© Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„
        try:
            if isinstance(backup_data, dict) and 'locale_files' in backup_data and backup_data['locale_files']:
                if AUDIT_AVAILABLE and user:
                    try:
                        log_audit(user, 'view', f'ØªØ­ØªÙˆÙŠ Ø§Ù„Ù†Ø³Ø®Ø© Ø¹Ù„Ù‰ {len(backup_data["locale_files"]) } Ù…Ù„Ù ØªØ±Ø¬Ù…Ø©. ÙŠØªØ·Ù„Ø¨ Ù†Ù‚Ù„Ù‡Ø§ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ locale.')
                    except Exception:
                        pass
        except Exception:
            pass
        return True
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©: {str(e)}")
        # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
        pd = get_restore_progress_data()
        pd.update({
            'status': 'error',
            'is_running': False,
            'error': str(e),
            'current_table': f'Ø®Ø·Ø£: {str(e)}'
        })
        set_restore_progress_data(pd)
        if AUDIT_AVAILABLE and user:
            try:
                log_audit(user, 'error', f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©: {str(e)}')
            except Exception:
                pass
        raise e


@login_required
def create_backup(request):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ø¹ ØªØªØ¨Ø¹ Ø§Ù„ØªÙ‚Ø¯Ù… ÙˆØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ù†Ø´Ø·Ø©"""
    
    logger.info(f"ğŸ¯ Ø¯Ø®ÙˆÙ„ create_backup: {request.method} - User: {request.user.username if request.user.is_authenticated else 'Anonymous'}")
    
    if request.method != 'POST':
        logger.warning(f"âŒ Ø·Ø±ÙŠÙ‚Ø© Ø·Ù„Ø¨ ØºÙŠØ± ØµØ­ÙŠØ­Ø©: {request.method}")
        if AUDIT_AVAILABLE:
            try:
                AuditLog.objects.create(
                    user=request.user if request.user.is_authenticated else None,
                    action='backup_access_denied',
                    details='Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØµÙˆÙ„ ØºÙŠØ± ØµØ­ÙŠØ­Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©'
                )
            except Exception:
                pass
        messages.error(request, _('Ø·Ø±ÙŠÙ‚Ø© Ø·Ù„Ø¨ ØºÙŠØ± ØµØ­ÙŠØ­Ø©'))
        return redirect('backup:backup_restore')
    
    progress_data = get_backup_progress_data()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©
    if progress_data.get('is_running', False):
        import time
        current_time = time.time()
        last_update = cache.get('backup_last_update', current_time)
        
        # Ø¥Ø°Ø§ Ù…Ø± Ø£ÙƒØ«Ø± Ù…Ù† Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ø¯ÙˆÙ† ØªØ­Ø¯ÙŠØ«ØŒ Ù‚Ù… Ø¨Ù…Ø³Ø­ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
        if current_time - last_update > 60:  # Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ§Ø­Ø¯Ø©
            cache.delete('backup_progress')
            cache.delete('backup_last_update')
            
            log_audit(request.user, 'delete', f'ØªÙ… Ù…Ø³Ø­ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ - Ø¹Ù…Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ©: {int(current_time - last_update)} Ø«Ø§Ù†ÙŠØ©')
            
            progress_data = get_backup_progress_data()  # Ø¥Ø¹Ø§Ø¯Ø© Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        else:
            # ÙØ­Øµ Ø¥Ø¶Ø§ÙÙŠ: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ© ØªØªÙ‚Ø¯Ù… ÙØ¹Ù„Ø§Ù‹
            current_percentage = progress_data.get('percentage', 0)
            last_percentage = cache.get('backup_last_percentage', 0)
            
            # Ø¥Ø°Ø§ Ù„Ù… ØªØªÙ‚Ø¯Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù„Ù…Ø¯Ø© 30 Ø«Ø§Ù†ÙŠØ©ØŒ ÙÙ‡ÙŠ Ù…Ø¹Ù„Ù‚Ø©
            if current_percentage == last_percentage and current_time - last_update > 30:
                cache.delete('backup_progress')
                cache.delete('backup_last_update')
                cache.delete('backup_last_percentage')
                
                log_audit(request.user, 'delete', f'ØªÙ… Ù…Ø³Ø­ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„Ù…ØªÙˆÙ‚ÙØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ - ØªÙˆÙ‚ÙØª Ø¹Ù†Ø¯ {current_percentage}%')
                
                progress_data = get_backup_progress_data()  # Ø¥Ø¹Ø§Ø¯Ø© Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            else:
                # ØªØ­Ø¯ÙŠØ« Ø¢Ø®Ø± Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ©
                cache.set('backup_last_percentage', current_percentage, timeout=3600)
                
                # Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ø§ Ø²Ø§Ù„Øª Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ - ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
                log_audit(request.user, 'error', f'Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¯Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø£Ø«Ù†Ø§Ø¡ ÙˆØ¬ÙˆØ¯ Ø¹Ù…Ù„ÙŠØ© Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ - Ù†Ø³Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²: {current_percentage}%')
                
                messages.error(request, _('Ø¹Ù…Ù„ÙŠØ© Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ù„ÙØ¹Ù„'))
                if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                    return JsonResponse({
                        'success': False,
                        'error': 'Ø¹Ù…Ù„ÙŠØ© Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ù„ÙØ¹Ù„'
                    })
                return redirect('backup:backup_restore')
    
    try:
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø®ØªØ§Ø±
        selected_format = (
            request.POST.get('format') or 
            request.POST.get('backupFormat') or 
            'json'
        ).strip().lower()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø­Ø³Ø¨ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚
        timestamp = dt_module.now().strftime('%Y%m%d_%H%M%S')
        
        if selected_format == 'xlsx':
            filename = f'backup_{timestamp}.xlsx'
            format_name = 'XLSX'
        else:
            filename = f'backup_{timestamp}.json'
            format_name = 'JSON'
            selected_format = 'json'
            
        # ØªØ³Ø¬ÙŠÙ„ Ø¨Ø¯Ø§ÙŠØ© Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
        log_audit(request.user, 'create', f'Ø·Ù„Ø¨ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¨ØµÙŠØºØ© {format_name}: {filename}')
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        backup_dir = os.path.join(settings.MEDIA_ROOT, 'backups')
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        
        filepath = os.path.join(backup_dir, filename)
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø© ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„ (Ù…Ø¨Ø³Ø·)
        def start_backup():
            try:
                # Ø¥Ø¶Ø§ÙØ© ØªØ£Ø®ÙŠØ± Ø¨Ø³ÙŠØ·
                import time
                time.sleep(0.5)
                
                # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù…Ø¨Ø§Ø´Ø± Ø¨Ø¯ÙˆÙ† ØªØ¹Ù‚ÙŠØ¯Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
                perform_backup_task(request.user, timestamp, filename, filepath, selected_format)
                
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {str(e)}")
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒØ§Ø´ Ø¨Ø§Ù„Ø®Ø·Ø£
                try:
                    from django.core.cache import cache
                    progress_data = {
                        'is_running': False,
                        'status': 'error',
                        'error': str(e),
                        'percentage': 0,
                        'current_table': f'Ø®Ø·Ø£: {str(e)}'
                    }
                    cache.set('backup_progress', progress_data, timeout=3600)
                except:
                    pass
                
        # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø®ÙŠØ·
        thread = threading.Thread(target=start_backup)
        thread.daemon = True
        thread.start()
        
        logger.info(f"ğŸ“ ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {filename}")
        
        # Ø¥Ø±Ø¬Ø§Ø¹ JSON response Ù„Ù„Ø·Ù„Ø¨Ø§Øª AJAX
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            return JsonResponse({
                'success': True,
                'filename': filename,
                'format': format_name,
                'message': f'ØªÙ… Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© {format_name}: {filename}'
            })
        
        messages.success(request, _(f'ØªÙ… Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© {format_name}: {filename}'))
        return redirect('backup:backup_restore')
        
    except Exception as e:
        error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {str(e)}"
        logger.error(error_msg)
        
        if AUDIT_AVAILABLE:
            try:
                AuditLog.objects.create(
                    user=request.user,
                    action='backup_error_request',
                    details=error_msg
                )
            except Exception:
                pass
        
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            return JsonResponse({
                'success': False,
                'error': error_msg
            })
        
        messages.error(request, error_msg)
        return redirect('backup:backup_restore')


@login_required  
def download_backup(request, filename):
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
    
    if not filename.endswith(('.json', '.xlsx')):
        raise Http404("Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…")
    
    backup_dir = os.path.join(settings.MEDIA_ROOT, 'backups')
    filepath = os.path.join(backup_dir, filename)
    
    if not os.path.exists(filepath):
        raise Http404("Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
    
    if AUDIT_AVAILABLE:
        try:
            AuditLog.objects.create(
                user=request.user,
                action='backup_download',
                details=f'ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {filename}'
            )
        except Exception:
            pass
    
    content_type = 'application/json' if filename.endswith('.json') else 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    
    try:
        with open(filepath, 'rb') as f:
            response = HttpResponse(f.read(), content_type=content_type)
            response['Content-Disposition'] = f'attachment; filename="{filename}"'
            return response
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù {filename}: {str(e)}")
        raise Http404("Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù")


@login_required
def delete_backup(request, filename):
    """Ø­Ø°Ù Ù…Ù„Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
    
    if request.method != 'POST':
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            return JsonResponse({
                'success': False,
                'error': 'Ø·Ø±ÙŠÙ‚Ø© Ø·Ù„Ø¨ ØºÙŠØ± ØµØ­ÙŠØ­Ø©'
            })
        return redirect('backup:backup_restore')
    
    if not filename.endswith(('.json', '.xlsx')):
        error_msg = "Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…"
        
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            return JsonResponse({
                'success': False,
                'error': error_msg
            })
        
        messages.error(request, error_msg)
        return redirect('backup:backup_restore')
    
    backup_dir = os.path.join(settings.MEDIA_ROOT, 'backups')
    filepath = os.path.join(backup_dir, filename)
    
    try:
        if os.path.exists(filepath):
            os.remove(filepath)
            
            # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø¯Ø« ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©
            log_audit(request.user, 'delete', f'Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {filename}')
            
            success_msg = f"ØªÙ… Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© {filename} Ø¨Ù†Ø¬Ø§Ø­"
            logger.info(f"âœ… {success_msg} - Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {request.user.username}")
            
            if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                return JsonResponse({
                    'success': True,
                    'message': success_msg
                })
                
            messages.success(request, success_msg)
        else:
            error_msg = "Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯"
            
            # ØªØ³Ø¬ÙŠÙ„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­Ø°Ù Ù„Ù„Ù…Ù„Ù ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
            log_audit(request.user, 'warning', f'Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ø°Ù Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {filename}')
            
            if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                return JsonResponse({
                    'success': False,
                    'error': error_msg
                })
                
            messages.error(request, error_msg)
            
    except Exception as e:
        error_msg = f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù: {str(e)}"
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù {filename}: {str(e)}")
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©
        log_audit(request.user, 'error', f'ÙØ´Ù„ Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {filename} - Ø®Ø·Ø£: {str(e)}')
        
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            return JsonResponse({
                'success': False,
                'error': error_msg
            })
        
        messages.error(request, error_msg)
    
    if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
        return JsonResponse({
            'success': True,
            'message': 'ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨'
        })
    
    return redirect('backup:backup_restore')


@login_required
def restore_backup(request):
    """Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
    
    if request.method != 'POST':
        messages.error(request, _("Ø·Ø±ÙŠÙ‚Ø© Ø·Ù„Ø¨ ØºÙŠØ± ØµØ­ÙŠØ­Ø©"))
        return redirect('backup:backup_restore')
    
    if not request.user.is_superuser:
        messages.error(request, _("ØºÙŠØ± Ù…Ø³Ù…ÙˆØ­ Ù„Ùƒ Ø¨Ø¥Ø¬Ø±Ø§Ø¡ Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©"))
        return redirect('backup:backup_restore')
    
    if 'backup_file' not in request.FILES and not request.POST.get('filename'):
        messages.error(request, _("ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ù…Ù„Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"))
        return redirect('backup:backup_restore')
    
    # Ù‚Ø¨ÙˆÙ„ Ø¹Ø¯Ø© ØµÙŠØº Ù„ØªÙ…Ø±ÙŠØ± Ù‚ÙŠÙ…Ø© clear_data Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£Ùˆ Ø§Ù„ AJAX (Ù…Ø«Ø§Ù„: 'on' Ù…Ù† form submissionØŒ 'true' Ù…Ù† AJAX)
    raw_clear = request.POST.get('clear_data')
    if raw_clear is None:
        clear_data = False
    else:
        try:
            clear_data = str(raw_clear).strip().lower() in ('true', '1', 'on', 'yes')
        except Exception:
            clear_data = False
    filename_from_list = request.POST.get('filename')
    backup_file = request.FILES.get('backup_file')
    
    try:
        if filename_from_list:
            # Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            backup_dir = os.path.join(settings.MEDIA_ROOT, 'backups')
            filepath = os.path.join(backup_dir, filename_from_list)
            if not os.path.exists(filepath):
                msg = _("Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
                if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                    return JsonResponse({'success': False, 'error': msg})
                messages.error(request, msg)
                return redirect('backup:backup_restore')
            if filepath.endswith('.json'):
                with open(filepath, 'r', encoding='utf-8') as f:
                    backup_data = json.load(f)
            elif filepath.endswith('.xlsx'):
                with open(filepath, 'rb') as f:
                    backup_data = load_backup_from_xlsx(f, user=request.user)
            else:
                msg = _("Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…")
                if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                    return JsonResponse({'success': False, 'error': msg})
                messages.error(request, msg)
                return redirect('backup:backup_restore')
            input_name_for_audit = filename_from_list
        elif backup_file and backup_file.name.endswith('.json'):
            file_content = backup_file.read().decode('utf-8')
            backup_data = json.loads(file_content)
            input_name_for_audit = backup_file.name
        elif backup_file and backup_file.name.endswith('.xlsx'):
            # Ø¯Ø¹Ù… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù…Ù„ÙØ§Øª Excel
            try:
                backup_data = load_backup_from_xlsx(backup_file, user=request.user)
                if AUDIT_AVAILABLE:
                    try:
                        AuditLog.objects.create(
                            user=request.user,
                            action='backup_restore_xlsx_parsed',
                            details=f'ØªÙ… ØªØ­ÙˆÙŠÙ„ Ù…Ù„Ù Excel Ù„Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©: {backup_file.name}'
                        )
                    except Exception:
                        pass
            except Exception as xlsx_error:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Excel: {str(xlsx_error)}")
                messages.error(request, _(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Excel: {str(xlsx_error)}"))
                if AUDIT_AVAILABLE:
                    try:
                        AuditLog.objects.create(
                            user=request.user,
                            action='backup_restore_xlsx_error',
                            details=f'ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ Ù…Ù„Ù Excel: {backup_file.name} - {str(xlsx_error)}'
                        )
                    except Exception:
                        pass
                return redirect('backup:backup_restore')
            input_name_for_audit = backup_file.name
        else:
            messages.error(request, _("Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…"))
            return redirect('backup:backup_restore')
        
        if AUDIT_AVAILABLE:
            try:
                AuditLog.objects.create(
                    user=request.user,
                    action='backup_restore_start',
                    details=f'Ø¨Ø¯Ø¡ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {input_name_for_audit}'
                )
            except Exception:
                pass
        
        # ØªØ´ØºÙŠÙ„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„ ÙˆØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù… Ø¹Ø¨Ø± Ø§Ù„ÙƒØ§Ø´
        def start_restore_task():
            try:
                perform_backup_restore(backup_data, clear_data, request.user)
                # Ø¹Ù†Ø¯ Ø§Ù„Ù†Ø¬Ø§Ø­ØŒ Ø³Ø¬Ù‘Ù„ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ (ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø°Ù„Ùƒ Ø¯Ø§Ø®Ù„ perform_backup_restore Ø£ÙŠØ¶Ø§Ù‹)
                if AUDIT_AVAILABLE:
                    try:
                        AuditLog.objects.create(
                            user=request.user,
                            action='backup_restore_complete',
                            details=f'ØªÙ… Ø¥ØªÙ…Ø§Ù… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­: {input_name_for_audit}'
                        )
                    except Exception:
                        pass
            except Exception as restore_error:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© (Ø®Ù„ÙÙŠØ©): {str(restore_error)}")
                if AUDIT_AVAILABLE:
                    try:
                        AuditLog.objects.create(
                            user=request.user,
                            action='backup_restore_failed',
                            details=f'ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {input_name_for_audit} - {str(restore_error)}'
                        )
                    except Exception:
                        pass

        thread = threading.Thread(target=start_restore_task, daemon=True)
        thread.start()

        # Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø·Ù„Ø¨
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            return JsonResponse({
                'success': True,
                'message': _('ØªÙ… Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©')
            })
        else:
            messages.info(request, _("ØªÙ… Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©ØŒ ÙŠÙ…ÙƒÙ† Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„ØªÙ‚Ø¯Ù… Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø©"))
            return redirect('backup:backup_restore')
        
    except json.JSONDecodeError:
        messages.error(request, _("Ù…Ù„Ù JSON ØºÙŠØ± ØµØ­ÙŠØ­"))
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {str(e)}")
        messages.error(request, _(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©: {str(e)}"))
    
    return redirect('backup:backup_restore')


@login_required
def get_restore_progress(request):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© ØªÙ‚Ø¯Ù… Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©"""
    try:
        progress_data = get_restore_progress_data()
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù„Ù‚Ø©
        if progress_data.get('is_running', False):
            import time
            current_time = time.time()
            last_update = cache.get('restore_last_update', current_time)
            if current_time - last_update > 600:
                cache.delete('restore_progress')
                cache.delete('restore_last_update')
                log_audit(request.user, 'delete', 'ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø¹Ù„Ù‚Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹')
        return JsonResponse({
            'success': True,
            'progress': progress_data
        })
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ ØªÙ‚Ø¯Ù… Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©: {str(e)}")
        return JsonResponse({'success': False, 'error': str(e)})


@login_required
def list_backups(request):
    """API Ù„Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
    
    try:
        backup_dir = os.path.join(settings.MEDIA_ROOT, 'backups')
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        
        backups = []
        for filename in os.listdir(backup_dir):
            if filename.endswith('.json') or filename.endswith('.xlsx'):
                filepath = os.path.join(backup_dir, filename)
                try:
                    stat = os.stat(filepath)
                    file_type = 'XLSX' if filename.endswith('.xlsx') else 'JSON'
                    backups.append({
                        'filename': filename,
                        'size': stat.st_size,
                        'size_formatted': filesizeformat(stat.st_size),
                        'created_at': dt_module.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                        'type': file_type,
                        'download_url': reverse('backup:download_backup', kwargs={'filename': filename})
                    })
                except (OSError, IOError):
                    continue
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†Ø³Ø® Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
        backups.sort(key=lambda x: x['created_at'], reverse=True)
        
        return JsonResponse({
            'success': True,
            'backups': backups,
            'count': len(backups)
        })
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {str(e)}")
        return JsonResponse({
            'success': False,
            'error': str(e)
        })