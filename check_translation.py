#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
from bs4 import BeautifulSoup
import time

def check_global_search_translation():
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ±Ø¬Ù…Ø© Global Search ÙÙŠ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""
    
    print("ğŸ” ÙØ­Øµ ØªØ±Ø¬Ù…Ø© Global Search ÙÙŠ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")
    print("=" * 50)
    
    try:
        # Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ ÙŠØ¹Ù…Ù„ Ø§Ù„Ø®Ø§Ø¯Ù…
        time.sleep(3)
        
        session = requests.Session()
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ØµÙØ­Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        arabic_url = "http://127.0.0.1:8001/ar/"
        
        print(f"ğŸ“¡ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰: {arabic_url}")
        
        response = session.get(arabic_url, timeout=10)
        
        if response.status_code == 200:
            print("âœ… ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ØµÙØ­Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Øµ ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
            search_links = soup.find_all('a', href='/ar/search/')
            
            if search_links:
                for link in search_links:
                    text_content = link.get_text(strip=True)
                    print(f"ğŸ” ÙˆØ¬Ø¯Øª Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨Ø­Ø«: '{text_content}'")
                    
                    if "Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù…" in text_content:
                        print("âœ… Ù…Ù…ØªØ§Ø²! Global Search Ù…ØªØ±Ø¬Ù… Ø¥Ù„Ù‰ 'Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù…'")
                        return True
                    elif "Global Search" in text_content:
                        print("âŒ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: Ù„Ø§ ÙŠØ²Ø§Ù„ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© 'Global Search'")
                        return False
                    else:
                        print(f"âš ï¸ Ù†Øµ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: '{text_content}'")
            else:
                print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨Ø­Ø«")
                
            # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ
            page_text = soup.get_text()
            if "Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù…" in page_text:
                print("âœ… 'Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù…' Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„ØµÙØ­Ø©")
                return True
            elif "Global Search" in page_text:
                print("âŒ 'Global Search' Ù„Ø§ ÙŠØ²Ø§Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©")
                return False
                
        else:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ØµÙØ­Ø©: ÙƒÙˆØ¯ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© {response.status_code}")
            
    except requests.exceptions.ConnectionError:
        print("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„Ø®Ø§Ø¯Ù… - ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Django ÙŠØ¹Ù…Ù„")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£: {e}")
    
    return False

if __name__ == "__main__":
    result = check_global_search_translation()
    if result:
        print("\nğŸ‰ Ø§Ù„Ù†ØªÙŠØ¬Ø©: Ø§Ù„ØªØ±Ø¬Ù…Ø© ØªØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­!")
    else:
        print("\nâš ï¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©: ÙŠØ­ØªØ§Ø¬ Ø¥ØµÙ„Ø§Ø­")
